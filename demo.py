#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ä¼˜åŒ–çš„å›¾ç‰‡åˆ†ç±»åŠŸèƒ½ - è§£å†³ä¸­æ–‡æ˜¾ç¤ºå’Œé¢„æµ‹æ•ˆæœé—®é¢˜
"""

import os
import sys
import cv2
import numpy as np
import matplotlib.pyplot as plt
from sklearn.neighbors import KNeighborsClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, classification_report
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler
import platform
import warnings
warnings.filterwarnings('ignore')

# ä¼˜åŒ–çš„ä¸­æ–‡å­—ä½“è®¾ç½®
def setup_chinese_font():
    """è®¾ç½®ä¸­æ–‡å­—ä½“æ”¯æŒï¼Œè§£å†³ä¹±ç é—®é¢˜"""
    import matplotlib.font_manager as fm
    
    system = platform.system()
    
    if system == "Windows":
        # Windowsç³»ç»Ÿå­—ä½“ä¼˜å…ˆçº§
        font_list = ['Microsoft YaHei', 'SimHei', 'SimSun', 'KaiTi']
    elif system == "Darwin":  # macOS
        font_list = ['PingFang SC', 'Hiragino Sans GB', 'STHeiti']
    else:  # Linux
        font_list = ['WenQuanYi Micro Hei', 'Noto Sans CJK SC', 'DejaVu Sans']
    
    # æ·»åŠ é»˜è®¤å­—ä½“ä½œä¸ºåå¤‡
    font_list.extend(['DejaVu Sans', 'Arial', 'sans-serif'])
    
    # å¼ºåˆ¶è®¾ç½®matplotlibå‚æ•°
    plt.rcParams.update({
        'font.sans-serif': font_list,
        'axes.unicode_minus': False,
        'figure.figsize': (10, 8),
        'figure.dpi': 100,
        'font.size': 12,
        'axes.titlesize': 16,
        'figure.titlesize': 18
    })
    
    # æ¸…é™¤matplotlibå­—ä½“ç¼“å­˜
    try:
        fm._rebuild()
    except:
        pass
    
    print(f"âœ… å­—ä½“è®¾ç½®å®Œæˆï¼Œå½“å‰ç³»ç»Ÿ: {system}")
    
    # æµ‹è¯•ä¸­æ–‡æ˜¾ç¤º
    try:
        fig, ax = plt.subplots(figsize=(1, 1))
        ax.text(0.5, 0.5, 'æµ‹è¯•', ha='center', va='center')
        plt.close(fig)
        print("âœ… ä¸­æ–‡å­—ä½“æµ‹è¯•é€šè¿‡")
    except Exception as e:
        print(f"âš ï¸ ä¸­æ–‡å­—ä½“æµ‹è¯•å¤±è´¥: {e}")

# åˆå§‹åŒ–å­—ä½“è®¾ç½®
setup_chinese_font()

# å¯¼å…¥é…ç½®
from config import config

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append(os.path.dirname(__file__))

class SimpleImageClassifier:
    """
    ç®€å•çš„å›¾ç‰‡åˆ†ç±»å™¨
    """
    
    def __init__(self, language='en'):
        # ä¼˜åŒ–çš„KNNåˆ†ç±»å™¨å‚æ•°
        self.classifier = KNeighborsClassifier(
            n_neighbors=5,  # å¢åŠ é‚»å±…æ•°é‡æé«˜ç¨³å®šæ€§
            weights='distance',  # ä½¿ç”¨è·ç¦»æƒé‡
            algorithm='auto'
        )
        self.data_dir = 'data'
        self.class_names = []
        self.is_trained = False
        self.scaler = StandardScaler()
        
        # ä¼˜åŒ–çš„SIFTå‚æ•°
        try:
            self.sift = cv2.SIFT_create(
                nfeatures=500,  # é™åˆ¶ç‰¹å¾ç‚¹æ•°é‡
                contrastThreshold=0.04,  # æé«˜å¯¹æ¯”åº¦é˜ˆå€¼
                edgeThreshold=10  # è¾¹ç¼˜é˜ˆå€¼
            )
        except Exception as e:
            print(f"âš ï¸ SIFTåˆå§‹åŒ–è­¦å‘Š: {e}")
            self.sift = cv2.SIFT_create()
            
        self.use_sift_features = True  # æ˜¯å¦ä½¿ç”¨SIFTç‰¹å¾
        self.language = language  # è¯­è¨€è®¾ç½®
        self.feature_cache = {}  # ç‰¹å¾ç¼“å­˜ï¼Œæé«˜æ€§èƒ½
    
    def extract_sift_features(self, image, dense_step=8):
        """
        ä¼˜åŒ–çš„Dense SIFTç‰¹å¾æå–
        """
        try:
            # å›¾åƒé¢„å¤„ç†
            if len(image.shape) == 3:
                gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
            else:
                gray = image.copy()
            
            # æ ‡å‡†åŒ–å›¾åƒå¤§å°
            gray = cv2.resize(gray, (256, 256))
            
            # åº”ç”¨é«˜æ–¯æ¨¡ç³Šå‡å°‘å™ªå£°
            gray = cv2.GaussianBlur(gray, (3, 3), 0)
            
            # ç›´æ–¹å›¾å‡è¡¡åŒ–å¢å¼ºå¯¹æ¯”åº¦
            gray = cv2.equalizeHist(gray)
            
            # æ–¹æ³•1: ä½¿ç”¨å¸¸è§„SIFTç‰¹å¾ç‚¹æ£€æµ‹
            keypoints, descriptors = self.sift.detectAndCompute(gray, None)
            
            if descriptors is not None and len(descriptors) > 10:
                # ä½¿ç”¨K-meansèšç±»ç”Ÿæˆè¯è¢‹æ¨¡å‹ç‰¹å¾
                n_clusters = min(50, len(descriptors))
                if n_clusters >= 2:
                    try:
                        kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)
                        kmeans.fit(descriptors)
                        
                        # ç”Ÿæˆç›´æ–¹å›¾ç‰¹å¾
                        labels = kmeans.labels_
                        hist, _ = np.histogram(labels, bins=n_clusters, range=(0, n_clusters))
                        feature_vector = hist.astype(np.float32)
                        
                        # å½’ä¸€åŒ–
                        if np.sum(feature_vector) > 0:
                            feature_vector = feature_vector / np.sum(feature_vector)
                        
                        # è¡¥å……ç»Ÿè®¡ç‰¹å¾
                        stats = [
                            np.mean(gray), np.std(gray), np.median(gray),
                            np.percentile(gray, 25), np.percentile(gray, 75)
                        ]
                        
                        return np.concatenate([feature_vector, stats])
                    except Exception as e:
                        print(f"âš ï¸ K-meansèšç±»å¤±è´¥: {e}")
                        # å›é€€åˆ°ç®€å•çš„æè¿°å­ç»Ÿè®¡
                        feature_vector = np.mean(descriptors, axis=0)
                        return feature_vector
                else:
                    # æè¿°å­å¤ªå°‘ï¼Œä½¿ç”¨å‡å€¼
                    feature_vector = np.mean(descriptors, axis=0)
                    return feature_vector
            else:
                # SIFTç‰¹å¾æå–å¤±è´¥ï¼Œä½¿ç”¨å¢å¼ºçš„åƒç´ ç‰¹å¾
                print("âš ï¸ SIFTç‰¹å¾ä¸è¶³ï¼Œä½¿ç”¨å¢å¼ºåƒç´ ç‰¹å¾")
                return self.extract_enhanced_pixel_features(gray)
                
        except Exception as e:
            print(f"âš ï¸ SIFTç‰¹å¾æå–å¤±è´¥: {e}ï¼Œä½¿ç”¨å¢å¼ºåƒç´ ç‰¹å¾")
            if len(image.shape) == 3:
                gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
            else:
                gray = image
            return self.extract_enhanced_pixel_features(gray)
    
    def extract_pixel_features(self, image):
        """
        æå–ç®€å•çš„åƒç´ ç‰¹å¾ï¼ˆå¤‡ç”¨æ–¹æ¡ˆï¼‰
        """
        if len(image.shape) == 3:
            image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        image = cv2.resize(image, (64, 64))
        return image.flatten()
    
    def extract_enhanced_pixel_features(self, image):
        """
        æå–å¢å¼ºçš„åƒç´ ç‰¹å¾ï¼ŒåŒ…å«å¤šç§ç»Ÿè®¡ç‰¹å¾
        """
        # åŸºç¡€åƒç´ ç‰¹å¾
        resized = cv2.resize(image, (32, 32))
        pixel_features = resized.flatten()
        
        # ç»Ÿè®¡ç‰¹å¾
        stats = [
            np.mean(image), np.std(image), np.median(image),
            np.min(image), np.max(image),
            np.percentile(image, 25), np.percentile(image, 75)
        ]
        
        # æ¢¯åº¦ç‰¹å¾
        grad_x = cv2.Sobel(image, cv2.CV_64F, 1, 0, ksize=3)
        grad_y = cv2.Sobel(image, cv2.CV_64F, 0, 1, ksize=3)
        gradient_magnitude = np.sqrt(grad_x**2 + grad_y**2)
        gradient_stats = [
            np.mean(gradient_magnitude), np.std(gradient_magnitude)
        ]
        
        # LBPç‰¹å¾ï¼ˆç®€åŒ–ç‰ˆï¼‰
        def simple_lbp(img, radius=1):
            h, w = img.shape
            lbp = np.zeros_like(img)
            for i in range(radius, h-radius):
                for j in range(radius, w-radius):
                    center = img[i, j]
                    code = 0
                    code |= (img[i-1, j-1] >= center) << 7
                    code |= (img[i-1, j] >= center) << 6
                    code |= (img[i-1, j+1] >= center) << 5
                    code |= (img[i, j+1] >= center) << 4
                    code |= (img[i+1, j+1] >= center) << 3
                    code |= (img[i+1, j] >= center) << 2
                    code |= (img[i+1, j-1] >= center) << 1
                    code |= (img[i, j-1] >= center) << 0
                    lbp[i, j] = code
            return lbp
        
        lbp = simple_lbp(image)
        lbp_hist, _ = np.histogram(lbp.flatten(), bins=16, range=(0, 256))
        lbp_hist = lbp_hist.astype(np.float32)
        if np.sum(lbp_hist) > 0:
            lbp_hist = lbp_hist / np.sum(lbp_hist)
        
        # åˆå¹¶æ‰€æœ‰ç‰¹å¾
        all_features = np.concatenate([
            pixel_features, stats, gradient_stats, lbp_hist
        ])
        
        return all_features
        
    def load_images(self):
        """
        ä»dataæ–‡ä»¶å¤¹åŠ è½½å›¾ç‰‡æ•°æ®
        """
        images = []
        labels = []
        
        if not os.path.exists(self.data_dir):
            print(f"é”™è¯¯ï¼šæ‰¾ä¸åˆ°æ•°æ®æ–‡ä»¶å¤¹ {self.data_dir}")
            return None, None
        
        # è·å–æ‰€æœ‰ç±»åˆ«æ–‡ä»¶å¤¹
        self.class_names = [d for d in os.listdir(self.data_dir) 
                           if os.path.isdir(os.path.join(self.data_dir, d))]
        self.class_names.sort()
        
        print(f"æ‰¾åˆ° {len(self.class_names)} ä¸ªç±»åˆ«: {self.class_names}")
        
        # åŠ è½½æ¯ä¸ªç±»åˆ«çš„å›¾ç‰‡
        for class_idx, class_name in enumerate(self.class_names):
            class_path = os.path.join(self.data_dir, class_name)
            image_files = [f for f in os.listdir(class_path) 
                          if f.lower().endswith(('.png', '.jpg', '.jpeg'))]
            
            print(f"åŠ è½½ç±»åˆ« {class_name}: {len(image_files)} å¼ å›¾ç‰‡")
            
            for image_file in image_files:
                image_path = os.path.join(class_path, image_file)
                image = cv2.imread(image_path)
                if image is not None:
                    # æ ¹æ®è®¾ç½®é€‰æ‹©ç‰¹å¾æå–æ–¹æ³•
                    if self.use_sift_features:
                        feature = self.extract_sift_features(image)
                    else:
                        feature = self.extract_pixel_features(image)
                    
                    images.append(feature)
                    labels.append(class_idx)
        
        return np.array(images), np.array(labels)
    
    def train_model(self):
        """
        è®­ç»ƒåˆ†ç±»æ¨¡å‹
        """
        print("\nğŸš€ å¼€å§‹è®­ç»ƒæ¨¡å‹...")
        
        # åŠ è½½å›¾ç‰‡æ•°æ®
        X, y = self.load_images()
        if X is None or len(X) == 0:
            print("âŒ æ²¡æœ‰æ‰¾åˆ°å›¾ç‰‡æ•°æ®")
            return
        
        print(f"æ€»å…±åŠ è½½äº† {len(X)} å¼ å›¾ç‰‡")
        print(f"ç‰¹å¾ç»´åº¦: {X.shape[1]}")
        
        # ç‰¹å¾æ ‡å‡†åŒ–
        print("æ­£åœ¨æ ‡å‡†åŒ–ç‰¹å¾...")
        X_scaled = self.scaler.fit_transform(X)
        
        # å¤„ç†å°æ•°æ®é›†çš„åˆ†å‰²é—®é¢˜
        if len(X) < 10:
            print("âš ï¸  æ•°æ®é›†è¾ƒå°ï¼Œä½¿ç”¨å…¨éƒ¨æ•°æ®è¿›è¡Œè®­ç»ƒå’Œæµ‹è¯•")
            X_train = X_test = X_scaled
            y_train = y_test = y
        else:
            try:
                # å°è¯•åˆ†å±‚æŠ½æ ·
                X_train, X_test, y_train, y_test = train_test_split(
                    X_scaled, y, test_size=0.3, random_state=42, stratify=y
                )
            except ValueError:
                # å¦‚æœåˆ†å±‚æŠ½æ ·å¤±è´¥ï¼Œä½¿ç”¨æ™®é€šåˆ†å‰²
                print("âš ï¸  æ— æ³•è¿›è¡Œåˆ†å±‚æŠ½æ ·ï¼Œä½¿ç”¨éšæœºåˆ†å‰²")
                X_train, X_test, y_train, y_test = train_test_split(
                    X_scaled, y, test_size=0.3, random_state=42
                )
        
        print(f"è®­ç»ƒé›†: {len(X_train)} å¼ å›¾ç‰‡")
        print(f"æµ‹è¯•é›†: {len(X_test)} å¼ å›¾ç‰‡")
        
        # è®­ç»ƒæ¨¡å‹
        feature_type = "Dense SIFT" if self.use_sift_features else "åƒç´ "
        print(f"æ­£åœ¨è®­ç»ƒKNNåˆ†ç±»å™¨ï¼ˆä½¿ç”¨{feature_type}ç‰¹å¾ï¼‰...")
        self.classifier.fit(X_train, y_train)
        
        # æµ‹è¯•æ¨¡å‹
        y_pred = self.classifier.predict(X_test)
        accuracy = accuracy_score(y_test, y_pred)
        
        print(f"\nâœ… æ¨¡å‹è®­ç»ƒå®Œæˆ!")
        print(f"ğŸ¯ æµ‹è¯•å‡†ç¡®ç‡: {accuracy:.2%}")
        
        # æ˜¾ç¤ºè¯¦ç»†åˆ†ç±»æŠ¥å‘Š
        print("\nğŸ“Š è¯¦ç»†åˆ†ç±»æŠ¥å‘Š:")
        report = classification_report(y_test, y_pred, target_names=self.class_names)
        print(report)
        
        self.is_trained = True
        return accuracy
    
    def predict_image(self, image_path=None):
        """
        é¢„æµ‹å•å¼ å›¾åƒ
        """
        if not self.is_trained:
            print("âŒ æ¨¡å‹å°šæœªè®­ç»ƒï¼Œè¯·å…ˆè®­ç»ƒæ¨¡å‹")
            return
        
        # å¦‚æœæ²¡æœ‰æŒ‡å®šå›¾ç‰‡è·¯å¾„ï¼Œè®©ç”¨æˆ·è¾“å…¥
        if image_path is None:
            image_path = input("è¯·è¾“å…¥å›¾åƒè·¯å¾„: ").strip()
        
        if not os.path.exists(image_path):
            print(f"âŒ å›¾åƒæ–‡ä»¶ä¸å­˜åœ¨: {image_path}")
            return
        
        try:
            # åŠ è½½å¹¶é¢„å¤„ç†å›¾åƒ
            image = cv2.imread(image_path)
            if image is None:
                print("âŒ æ— æ³•è¯»å–å›¾åƒæ–‡ä»¶")
                return
            
            # æå–ç‰¹å¾
            if self.use_sift_features:
                feature = self.extract_sift_features(image)
            else:
                feature = self.extract_pixel_features(image)
            
            # æ ‡å‡†åŒ–ç‰¹å¾
            feature = self.scaler.transform(feature.reshape(1, -1))
            
            # é¢„æµ‹
            prediction = self.classifier.predict(feature)[0]
            probabilities = self.classifier.predict_proba(feature)[0]
            
            predicted_class = self.class_names[prediction]
            confidence = probabilities[prediction]
            
            print(f"\n{config.get_display_text('prediction_result', self.language)}")
            print(config.get_display_text('predicted_class', self.language).format(predicted_class))
            print(config.get_display_text('confidence', self.language).format(confidence))
            
            print(f"\n{config.get_display_text('class_probabilities', self.language)}")
            for i, (class_name, prob) in enumerate(zip(self.class_names, probabilities)):
                bar = "â–ˆ" * int(prob * 20)  # ç®€å•çš„æ¡å½¢å›¾
                print(f"  {class_name:10s}: {prob:.2%} {bar}")
            
            # æ˜¾ç¤ºå›¾åƒ
            self.show_image(image_path, predicted_class, confidence)
            
            return predicted_class, confidence
            
        except Exception as e:
            print(f"âŒ é¢„æµ‹è¿‡ç¨‹å‡ºé”™: {str(e)}")
            return None, None
    
    def show_image(self, image_path, predicted_class, confidence):
        """
        ä¼˜åŒ–çš„å›¾åƒæ˜¾ç¤ºåŠŸèƒ½ï¼Œè§£å†³ä¸­æ–‡ä¹±ç é—®é¢˜
        """
        try:
            # è¯»å–å›¾åƒ
            image = cv2.imread(image_path)
            if image is not None:
                image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
                
                # é‡æ–°è®¾ç½®å­—ä½“ç¡®ä¿æ˜¾ç¤ºæ­£ç¡®
                plt.rcParams['font.sans-serif'] = ['Microsoft YaHei', 'SimHei', 'SimSun', 'DejaVu Sans']
                plt.rcParams['axes.unicode_minus'] = False
                
                # åˆ›å»ºå›¾åƒæ˜¾ç¤º
                fig = plt.figure(figsize=(10, 8))
                plt.imshow(image, cmap='gray' if len(image.shape) == 2 else None)
                
                # è®¾ç½®æ ‡é¢˜ï¼ˆè§£å†³ä¸­æ–‡æ˜¾ç¤ºé—®é¢˜ï¼‰
                if self.language == 'en':
                    title_text = f'Prediction Result: {predicted_class}\nConfidence: {confidence:.2%}'
                else:
                    title_text = f'é¢„æµ‹ç»“æœ: {predicted_class}\nç½®ä¿¡åº¦: {confidence:.2%}'
                
                # å¼ºåˆ¶è®¾ç½®å­—ä½“å±æ€§
                plt.title(title_text, fontsize=16, pad=20, 
                         fontproperties='Microsoft YaHei' if platform.system() == 'Windows' else 'DejaVu Sans')
                plt.axis('off')
                
                # æ·»åŠ å›¾åƒä¿¡æ¯
                info_text = f'Image: {os.path.basename(image_path)}\nSize: {image.shape[1]}x{image.shape[0]}'
                plt.figtext(0.02, 0.02, info_text, fontsize=10, 
                           bbox=dict(boxstyle="round,pad=0.3", facecolor="lightgray", alpha=0.8),
                           fontproperties='Microsoft YaHei' if platform.system() == 'Windows' else 'DejaVu Sans')
                
                # è®¾ç½®çª—å£æ ‡é¢˜
                if hasattr(fig.canvas, 'manager'):
                    if self.language == 'en':
                        fig.canvas.manager.set_window_title(f'Classification Result - {predicted_class}')
                    else:
                        fig.canvas.manager.set_window_title(f'åˆ†ç±»ç»“æœ - {predicted_class}')
                
                plt.tight_layout()
                plt.show(block=False)  # éé˜»å¡æ˜¾ç¤º
                
                # è¯¢é—®æ˜¯å¦ç»§ç»­
                input("\næŒ‰å›è½¦é”®ç»§ç»­...")
                plt.close()
            else:
                print("âŒ æ— æ³•è¯»å–å›¾åƒæ–‡ä»¶")
            
        except Exception as e:
            print(f"âŒ æ˜¾ç¤ºå›¾åƒæ—¶å‡ºé”™: {str(e)}")
            print(f"   å›¾åƒè·¯å¾„: {image_path}")
            print(f"   é¢„æµ‹ç»“æœ: {predicted_class} (ç½®ä¿¡åº¦: {confidence:.2%})")
    
    def select_language(self):
        """é€‰æ‹©ç•Œé¢è¯­è¨€"""
        print("\n=== Language Selection / è¯­è¨€é€‰æ‹© ===")
        print("1. English")
        print("2. ä¸­æ–‡")
        
        while True:
            choice = input("Please select language / è¯·é€‰æ‹©è¯­è¨€ (1/2): ").strip()
            if choice == '1':
                self.language = 'en'
                print("âœ… English selected")
                break
            elif choice == '2':
                self.language = 'zh'
                print("âœ… å·²é€‰æ‹©ä¸­æ–‡")
                break
            else:
                print("âŒ Invalid choice / æ— æ•ˆé€‰æ‹©, please enter 1 or 2 / è¯·è¾“å…¥1æˆ–2")
    
    def run_demo(self):
        """
        ä¼˜åŒ–çš„æ¼”ç¤ºæµç¨‹ï¼Œæä¾›æ›´å¥½çš„ç”¨æˆ·ä½“éªŒ
        """
        print("\n" + "="*60)
        print("ğŸ¯ ChladniVision ä¼˜åŒ–ç‰ˆå›¾åƒåˆ†ç±»æ¼”ç¤º")
        print("   è§£å†³ä¸­æ–‡æ˜¾ç¤ºé—®é¢˜ï¼Œæå‡é¢„æµ‹å‡†ç¡®æ€§")
        print("="*60)
        
        # è¯­è¨€é€‰æ‹©
        self.select_language()
        
        print(f"\n=== {config.get_display_text('title', self.language)} ===")
        print(f"\nğŸ”§ {config.get_display_text('feature_selection', self.language)}")
        print(f"   {config.get_display_text('sift_option', self.language)}")
        print(f"   {config.get_display_text('pixel_option', self.language)}")
        
        while True:
            choice = input(f"\n{config.get_display_text('select_method', self.language)}").strip()
            if choice == '1':
                print(f"\nâœ… {config.get_display_text('sift_selected', self.language)}")
                self.use_sift_features = True
                break
            elif choice == '2':
                print(f"\nâœ… {config.get_display_text('pixel_selected', self.language)}")
                self.use_sift_features = False
                break
            else:
                print(f"âŒ {config.get_display_text('invalid_choice', self.language)}")
        
        print(f"\n{config.get_display_text('training_start', self.language)}")
        accuracy = self.train_model()
        
        if accuracy is None:
            print(f"âŒ {config.get_display_text('training_failed', self.language)}")
            return
        
        print("\n" + "="*60)
        print(f"ğŸ‰ {config.get_display_text('training_complete', self.language)}")
        print(f"ğŸ“Š æ¨¡å‹å‡†ç¡®ç‡: {accuracy:.2%}")
        print("="*60)
        
        # æä¾›ç¤ºä¾‹å›¾ç‰‡è·¯å¾„æç¤º
        if os.path.exists(self.data_dir):
            print("\nğŸ’¡ ç¤ºä¾‹å›¾ç‰‡è·¯å¾„:")
            for class_name in self.class_names[:3]:  # æ˜¾ç¤ºå‰3ä¸ªç±»åˆ«
                class_path = os.path.join(self.data_dir, class_name)
                if os.path.exists(class_path):
                    files = [f for f in os.listdir(class_path) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]
                    if files:
                        example_path = os.path.join(class_path, files[0])
                        print(f"   {class_name}: {example_path}")
        
        while True:
            print(f"\nğŸ“‹ {config.get_display_text('select_operation', self.language)}")
            print("   2-æŸ¥çœ‹æ¨¡å‹ä¿¡æ¯")
            choice = input("è¯·é€‰æ‹© (0-é€€å‡º, 1-é¢„æµ‹å›¾ç‰‡, 2-æ¨¡å‹ä¿¡æ¯): ").strip()
            
            if choice == '0':
                print(f"\nğŸ‘‹ {config.get_display_text('goodbye', self.language)}")
                break
            elif choice == '1':
                image_path = input(f"\n{config.get_display_text('enter_path', self.language)}").strip()
                
                # å¤„ç†å¼•å·
                image_path = image_path.strip('"\'')
                
                if image_path and os.path.exists(image_path):
                    print(f"\nğŸ” æ­£åœ¨åˆ†æå›¾åƒ: {os.path.basename(image_path)}")
                    self.predict_image(image_path)
                else:
                    print(f"âŒ {config.get_display_text('file_not_found', self.language)}")
                    print(f"   è¾“å…¥çš„è·¯å¾„: {image_path}")
            elif choice == '2':
                self.show_model_info()
            else:  
                print(f"âŒ {config.get_display_text('invalid_choice', self.language)}")
    
    def show_model_info(self):
        """
        æ˜¾ç¤ºæ¨¡å‹ä¿¡æ¯
        """
        print("\n" + "="*50)
        print("ğŸ“Š æ¨¡å‹ä¿¡æ¯")
        print("="*50)
        print(f"ğŸ”§ åˆ†ç±»å™¨: KNN (k={self.classifier.n_neighbors})")
        print(f"ğŸ“ æ•°æ®ç›®å½•: {self.data_dir}")
        print(f"ğŸ·ï¸  ç±»åˆ«æ•°é‡: {len(self.class_names)}")
        print(f"ğŸ“‹ ç±»åˆ«åˆ—è¡¨: {', '.join(self.class_names)}")
        print(f"ğŸ¯ ç‰¹å¾ç±»å‹: {'ä¼˜åŒ–SIFTç‰¹å¾' if self.use_sift_features else 'å¢å¼ºåƒç´ ç‰¹å¾'}")
        print(f"âœ… è®­ç»ƒçŠ¶æ€: {'å·²è®­ç»ƒ' if self.is_trained else 'æœªè®­ç»ƒ'}")
        print(f"ğŸŒ ç•Œé¢è¯­è¨€: {'ä¸­æ–‡' if self.language == 'zh' else 'English'}")
    



def main():
    """
    ä¸»å‡½æ•°
    """
    # åˆ›å»ºåˆ†ç±»å™¨å®ä¾‹
    classifier = SimpleImageClassifier()
    
    # è¿è¡Œæ¼”ç¤º
    classifier.run_demo()


if __name__ == "__main__":
    main()