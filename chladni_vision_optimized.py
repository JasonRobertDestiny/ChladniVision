#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ChladniVision Optimized - ä¼˜åŒ–ç‰ˆæ ¸å¿ƒç³»ç»Ÿ
ä¸“æ³¨äºé«˜ç²¾åº¦åˆ†ç±»å’Œä¼˜ç§€æ€§èƒ½
"""

import os
import sys
import cv2
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.svm import SVC
from sklearn.neural_network import MLPClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA
import joblib
from tqdm import tqdm
from datetime import datetime
import argparse
from collections import Counter
import warnings
from pathlib import Path

# å¯¼å…¥ä¼˜åŒ–ç‰ˆç‰¹å¾æå–å™¨
from src.feature_extractor_optimized import OptimizedFeatureExtractor

# ä¿®å¤Windowsç³»ç»Ÿjoblibå¹¶è¡Œå¤„ç†é—®é¢˜
os.environ['LOKY_MAX_CPU_COUNT'] = '4'  # é™åˆ¶æœ€å¤§CPUæ ¸å¿ƒæ•°
os.environ['JOBLIB_START_METHOD'] = 'threading'  # ä½¿ç”¨threadingè€Œä¸æ˜¯multiprocessing
os.environ['OMP_NUM_THREADS'] = '4'  # é™åˆ¶OpenMPçº¿ç¨‹æ•°

warnings.filterwarnings('ignore')

# è®¾ç½®è‹±æ–‡å­—ä½“
plt.rcParams['font.sans-serif'] = ['DejaVu Sans', 'Arial', 'Helvetica']
plt.rcParams['axes.unicode_minus'] = False
plt.rcParams['font.family'] = 'sans-serif'

class ChladniVisionOptimized:
    """ä¼˜åŒ–ç‰ˆChladniVisionç³»ç»Ÿ"""
    
    def __init__(self):
        """åˆå§‹åŒ–ç³»ç»Ÿ"""
        self.model = None
        self.feature_extractor = OptimizedFeatureExtractor()
        self.class_names = []
        self.is_trained = False
        self.model_info = {}
        self.image_size = (128, 128)
        self.output_dir = "output_optimized"
        self.prediction_history = []
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        os.makedirs(self.output_dir, exist_ok=True)
        
        # åˆ›å»ºå­ç›®å½•
        self.training_dir = os.path.join(self.output_dir, "training")
        self.predictions_dir = os.path.join(self.output_dir, "predictions")
        self.reports_dir = os.path.join(self.output_dir, "reports")
        
        os.makedirs(self.training_dir, exist_ok=True)
        os.makedirs(self.predictions_dir, exist_ok=True)
        os.makedirs(self.reports_dir, exist_ok=True)
        
        # æ¨¡å‹é…ç½®
        self.model_config = {
            'use_ensemble': True,
            'cross_validation': True,
            'hyperparameter_tuning': True,
            'feature_selection': True
        }
    
    def welcome_message(self):
        """æ˜¾ç¤ºæ¬¢è¿ä¿¡æ¯"""
        print("=" * 70)
        print("ğŸš€ ChladniVision Optimized - ä¼˜åŒ–ç‰ˆç³»ç»Ÿ")
        print("   é«˜ç²¾åº¦ç‰¹å¾æå– | æ™ºèƒ½æ¨¡å‹é€‰æ‹© | ä¸“ä¸šå¯è§†åŒ–")
        print("=" * 70)
        print("")
        print("ğŸŒŸ æ ¸å¿ƒä¼˜åŒ–:")
        print("   âœ… 10ç§é«˜çº§ç‰¹å¾æå–æ–¹æ³•")
        print("   âœ… æ™ºèƒ½é›†æˆå­¦ä¹ æ¨¡å‹")
        print("   âœ… è‡ªåŠ¨è¶…å‚æ•°ä¼˜åŒ–")
        print("   âœ… é²æ£’ç‰¹å¾å¤„ç†")
        print("   âœ… ä¸“ä¸šçº§å¯è§†åŒ–åˆ†æ")
        print("   âœ… å®æ—¶é¢„æµ‹ä¸æ‰¹é‡å¤„ç†")
        print("")
    
    def load_dataset(self, data_dir):
        """åŠ è½½æ•°æ®é›†"""
        print(f"ğŸ“ åŠ è½½æ•°æ®é›†: {data_dir}")
        
        if not os.path.exists(data_dir):
            print("âŒ æ•°æ®ç›®å½•ä¸å­˜åœ¨")
            return None, None, None
        
        images = []
        labels = []
        paths = []
        
        # æ£€æŸ¥æ•°æ®é›†ç»“æ„
        if 'train' in os.listdir(data_dir) and 'test' in os.listdir(data_dir):
            # train/test ç»“æ„
            for split in ['train', 'test']:
                split_dir = os.path.join(data_dir, split)
                if not os.path.exists(split_dir):
                    continue
                
                print(f"   å¤„ç† {split} æ•°æ®...")
                freq_dirs = [d for d in os.listdir(split_dir) 
                           if os.path.isdir(os.path.join(split_dir, d))]
                
                for freq in freq_dirs:
                    freq_dir = os.path.join(split_dir, freq)
                    self._load_images_from_dir(freq_dir, freq, images, labels, paths)
        else:
            # é¢‘ç‡ç›®å½•ç»“æ„
            print("   å¤„ç†é¢‘ç‡ç›®å½•...")
            freq_dirs = [d for d in os.listdir(data_dir) 
                       if os.path.isdir(os.path.join(data_dir, d)) and d not in ['output', 'models', '__pycache__']]
            
            for freq in freq_dirs:
                freq_dir = os.path.join(data_dir, freq)
                self._load_images_from_dir(freq_dir, freq, images, labels, paths)
        
        if not images:
            print("âŒ æœªæ‰¾åˆ°å›¾åƒæ–‡ä»¶")
            return None, None, None
        
        print(f"   âœ… åŠ è½½ {len(images)} å¼ å›¾åƒ")
        class_counts = Counter(labels)
        print("   ç±»åˆ«åˆ†å¸ƒ:")
        for class_name, count in class_counts.items():
            print(f"      {class_name}: {count} å¼ ")
        
        self.class_names = sorted(list(set(labels)))
        return images, np.array(labels), paths
    
    def _load_images_from_dir(self, dir_path, label, images, labels, paths):
        """ä»ç›®å½•åŠ è½½å›¾åƒ"""
        if not os.path.exists(dir_path):
            return
        
        image_files = [f for f in os.listdir(dir_path) 
                     if f.lower().endswith(('.png', '.jpg', '.jpeg'))]
        
        for filename in tqdm(image_files, desc=f"      {label}", leave=False):
            image_path = os.path.join(dir_path, filename)
            
            try:
                # è¯»å–å›¾åƒ
                image = cv2.imread(image_path)
                if image is None:
                    continue
                
                images.append(image)
                labels.append(label)
                paths.append(image_path)
                
            except Exception as e:
                continue
    
    def train_ensemble_model(self, X_features, y):
        """è®­ç»ƒé›†æˆæ¨¡å‹"""
        print("ğŸ¤– è®­ç»ƒæ™ºèƒ½é›†æˆæ¨¡å‹...")
        
        # åŸºç¡€æ¨¡å‹
        base_models = {
            'RandomForest': RandomForestClassifier(n_estimators=200, random_state=42),
            'SVM': SVC(C=10, gamma='scale', kernel='rbf', random_state=42, probability=True),
            'MLP': MLPClassifier(hidden_layer_sizes=(100, 50), random_state=42, max_iter=1000),
            'GradientBoosting': GradientBoostingClassifier(n_estimators=100, random_state=42)
        }
        
        # è®­ç»ƒæ¯ä¸ªæ¨¡å‹
        trained_models = {}
        model_scores = {}
        
        for name, model in base_models.items():
            try:
                print(f"   è®­ç»ƒ {name}...")
                
                # äº¤å‰éªŒè¯
                if self.model_config['cross_validation']:
                    cv_scores = cross_val_score(model, X_features, y, cv=5, scoring='accuracy')
                    mean_score = cv_scores.mean()
                    std_score = cv_scores.std()
                else:
                    # ç®€å•è®­ç»ƒéªŒè¯
                    X_train, X_val, y_train, y_val = train_test_split(
                        X_features, y, test_size=0.2, random_state=42
                    )
                    model.fit(X_train, y_train)
                    mean_score = model.score(X_val, y_val)
                    std_score = 0.0
                
                # è®­ç»ƒå®Œæ•´æ¨¡å‹
                model.fit(X_features, y)
                trained_models[name] = model
                model_scores[name] = {
                    'mean_score': mean_score,
                    'std_score': std_score,
                    'model': model
                }
                
                print(f"      {name}: {mean_score:.4f} (Â±{std_score:.4f})")
                
            except Exception as e:
                print(f"      {name}: è®­ç»ƒå¤±è´¥ - {e}")
        
        # é€‰æ‹©æœ€ä½³æ¨¡å‹
        best_name = max(model_scores.keys(), key=lambda x: model_scores[x]['mean_score'])
        best_model = trained_models[best_name]
        best_score = model_scores[best_name]['mean_score']
        
        print(f"   ğŸŒŸ æœ€ä½³æ¨¡å‹: {best_name} (å‡†ç¡®ç‡: {best_score:.4f})")
        
        # å¦‚æœå¯ç”¨é›†æˆå­¦ä¹ 
        if self.model_config['use_ensemble'] and len(trained_models) > 1:
            # åˆ›å»ºé›†æˆæ¨¡å‹
            ensemble_models = list(trained_models.values())
            self.model = EnsembleModel(ensemble_models)
            print("   ğŸ”„ å¯ç”¨é›†æˆå­¦ä¹ æ¨¡å‹")
        else:
            self.model = best_model
        
        self.model_info = {
            'best_model': best_name,
            'best_score': best_score,
            'all_scores': model_scores,
            'is_ensemble': self.model_config['use_ensemble']
        }
        
        return best_model
    
    def train(self, data_dir, model_path='demo_optimized_model.pkl'):
        """è®­ç»ƒæ¨¡å‹"""
        print(f"\nğŸš€ å¼€å§‹è®­ç»ƒä¼˜åŒ–ç‰ˆæ¨¡å‹...")
        print(f"   æ•°æ®ç›®å½•: {data_dir}")
        
        start_time = datetime.now()
        
        try:
            # åŠ è½½æ•°æ®
            X_images, y, paths = self.load_dataset(data_dir)
            if X_images is None:
                return False
            
            # æ£€æŸ¥æ•°æ®é‡
            class_counts = Counter(y)
            min_samples = min(class_counts.values())
            
            if min_samples < 2:
                print(f"âŒ è®­ç»ƒå¤±è´¥: æŸäº›ç±»åˆ«æ ·æœ¬å¤ªå°‘ (æœ€å°‘: {min_samples} ä¸ª)")
                return False
            
            # æå–ç‰¹å¾
            X_features = self.feature_extractor.extract_all_features(X_images)
            
            # ç‰¹å¾ä¼˜åŒ–
            X_optimized = self.feature_extractor.optimize_features(X_features)
            
            # è®­ç»ƒæ¨¡å‹
            self.train_ensemble_model(X_optimized, y)
            
            # è¯„ä¼°æ¨¡å‹
            print("ğŸ“Š è¯„ä¼°æ¨¡å‹æ€§èƒ½...")
            y_pred = self.model.predict(X_optimized)
            accuracy = accuracy_score(y, y_pred)
            
            # ç”Ÿæˆå¯è§†åŒ–
            self.generate_enhanced_visualizations(y, y_pred, paths, X_optimized)
            
            # è®¾ç½®è®­ç»ƒæ ‡å¿—å¹¶ä¿å­˜æ¨¡å‹
            self.is_trained = True
            self.save_model(model_path)
            
            training_time = (datetime.now() - start_time).total_seconds()
            
            print(f"\nğŸ‰ è®­ç»ƒå®Œæˆ!")
            print(f"   â±ï¸ è®­ç»ƒæ—¶é—´: {training_time:.2f} ç§’")
            print(f"   ğŸ“Š è®­ç»ƒå‡†ç¡®ç‡: {accuracy:.4f}")
            print(f"   ğŸ¯ æœ€ä½³æ¨¡å‹: {self.model_info['best_model']}")
            print(f"   ğŸ’¾ æ¨¡å‹å·²ä¿å­˜: {model_path}")
            
            return True
            
        except Exception as e:
            print(f"âŒ è®­ç»ƒå¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return False
    
    def predict(self, image_path, save_result=True):
        """é¢„æµ‹å›¾åƒ"""
        if not self.is_trained:
            print("âŒ æ¨¡å‹å°šæœªè®­ç»ƒ")
            return None
        
        try:
            print(f"ğŸ¯ é¢„æµ‹å›¾åƒ: {image_path}")
            
            # è¯»å–å›¾åƒ
            image = cv2.imread(image_path)
            if image is None:
                print(f"âŒ æ— æ³•è¯»å–å›¾åƒ: {image_path}")
                return None
            
            # é¢„å¤„ç†
            processed_image = self.feature_extractor.preprocess_image(image)
            
            # æå–ç‰¹å¾
            feature_vector = self.feature_extractor.extract_all_features([processed_image])
            
            # ç‰¹å¾ä¼˜åŒ–
            feature_optimized = self.feature_extractor.transform_features(feature_vector)
            
            # é¢„æµ‹
            prediction = self.model.predict(feature_optimized)[0]
            
            # è·å–ç½®ä¿¡åº¦
            if hasattr(self.model, 'predict_proba'):
                probabilities = self.model.predict_proba(feature_optimized)[0]
                confidence = np.max(probabilities)
                prob_dict = dict(zip(self.class_names, probabilities))
            else:
                confidence = 1.0
                prob_dict = {prediction: 1.0}
            
            result = {
                'predicted_class': prediction,
                'confidence': confidence,
                'probabilities': prob_dict
            }
            
            # è®°å½•é¢„æµ‹å†å²
            self.prediction_history.append({
                'timestamp': datetime.now(),
                'image_path': image_path,
                'prediction': prediction,
                'confidence': confidence,
                'probabilities': prob_dict.copy()
            })
            
            # æ˜¾ç¤ºç»“æœ
            print(f"   ğŸ¯ é¢„æµ‹ç»“æœ: {prediction}")
            print(f"   ğŸ² ç½®ä¿¡åº¦: {confidence:.4f}")
            
            print("   ğŸ“Š å„ç±»åˆ«æ¦‚ç‡:")
            sorted_probs = sorted(prob_dict.items(), key=lambda x: x[1], reverse=True)
            for class_name, prob in sorted_probs:
                bar_length = int(prob * 40)
                bar = "â–ˆ" * bar_length + "â–‘" * (40 - bar_length)
                print(f"      {class_name:8s}: {prob:.4f} {bar}")
            
            # ä¿å­˜å¯è§†åŒ–ç»“æœ
            if save_result:
                self.save_prediction_visualization(image, result, image_path)
            
            return result
            
        except Exception as e:
            print(f"âŒ é¢„æµ‹å¤±è´¥: {e}")
            return None
    
    def save_prediction_visualization(self, image, result, image_path):
        """ä¿å­˜é¢„æµ‹å¯è§†åŒ–"""
        try:
            fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(12, 10))
            
            # åŸå§‹å›¾åƒ
            image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
            ax1.imshow(image_rgb)
            ax1.set_title('Original Image', fontsize=14, fontweight='bold')
            ax1.axis('off')
            
            # é¢„æµ‹ç»“æœ
            ax2.text(0.5, 0.5, f'Prediction: {result["predicted_class"]}', 
                    transform=ax2.transAxes, fontsize=16, fontweight='bold',
                    ha='center', va='center')
            ax2.text(0.5, 0.3, f'Confidence: {result["confidence"]:.4f}', 
                    transform=ax2.transAxes, fontsize=12,
                    ha='center', va='center')
            ax2.set_title('Prediction Result', fontsize=14, fontweight='bold')
            ax2.axis('off')
            
            # æ¦‚ç‡åˆ†å¸ƒ
            probs = list(result['probabilities'].values())
            classes = list(result['probabilities'].keys())
            bars = ax3.bar(classes, probs, color='skyblue', alpha=0.7)
            ax3.set_title('Class Probability Distribution', fontsize=14, fontweight='bold')
            ax3.set_ylabel('Probability')
            ax3.set_ylim(0, 1)
            
            # é¢„æµ‹å†å²
            if len(self.prediction_history) > 1:
                confidences = [p['confidence'] for p in self.prediction_history[-10:]]
                times = [p['timestamp'].strftime('%H:%M:%S') for p in self.prediction_history[-10:]]
                ax4.plot(times, confidences, 'o-', color='green', linewidth=2, markersize=6)
                ax4.set_title('Prediction Confidence History', fontsize=12, fontweight='bold')
                ax4.set_ylabel('Confidence')
                ax4.set_ylim(0, 1)
                plt.setp(ax4.get_xticklabels(), rotation=45)
            else:
                ax4.text(0.5, 0.5, 'History will appear after more predictions', 
                        ha='center', va='center', transform=ax4.transAxes, fontsize=12)
                ax4.axis('off')
            
            plt.tight_layout()
            
            # ä¿å­˜ç»“æœ
            image_name = os.path.splitext(os.path.basename(image_path))[0]
            output_path = f"{self.predictions_dir}/prediction_{image_name}.png"
            plt.savefig(output_path, dpi=300, bbox_inches='tight')
            plt.close()
            
            print(f"   ğŸ’¾ é¢„æµ‹ç»“æœå·²ä¿å­˜: {output_path}")
            
        except Exception as e:
            print(f"   âŒ å¯è§†åŒ–ä¿å­˜å¤±è´¥: {e}")
    
    def generate_enhanced_visualizations(self, y_true, y_pred, paths, X_features):
        """ç”Ÿæˆå¢å¼ºçš„å¯è§†åŒ–"""
        print("ğŸ¨ ç”Ÿæˆå¢å¼ºå¯è§†åŒ–ç»“æœ...")
        
        try:
            # 1. æ··æ·†çŸ©é˜µ
            self.create_confusion_matrix(y_true, y_pred)
            
            # 2. æ¨¡å‹æ€§èƒ½å¯¹æ¯”
            self.create_model_comparison()
            
            # 3. ç‰¹å¾åˆ†æ
            self.create_feature_analysis(X_features)
            
            # 4. è®­ç»ƒæ‘˜è¦
            self.create_training_summary(y_true, y_pred)
            
            print(f"   âœ… å¯è§†åŒ–ç»“æœå·²ä¿å­˜åˆ° {self.output_dir}/ ç›®å½•")
            
        except Exception as e:
            print(f"   âŒ å¯è§†åŒ–ç”Ÿæˆå¤±è´¥: {e}")
    
    def create_confusion_matrix(self, y_true, y_pred):
        """åˆ›å»ºæ··æ·†çŸ©é˜µ"""
        cm = confusion_matrix(y_true, y_pred)
        
        plt.figure(figsize=(10, 8))
        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
                   xticklabels=self.class_names,
                   yticklabels=self.class_names)
        plt.title('Confusion Matrix', fontsize=16, fontweight='bold')
        plt.xlabel('Predicted Class', fontsize=12)
        plt.ylabel('True Class', fontsize=12)
        
        plt.tight_layout()
        plt.savefig(f'{self.training_dir}/confusion_matrix.png', dpi=300, bbox_inches='tight')
        plt.close()
    
    def create_model_comparison(self):
        """åˆ›å»ºæ¨¡å‹å¯¹æ¯”å›¾è¡¨"""
        if 'all_scores' not in self.model_info:
            return
        
        model_scores = self.model_info['all_scores']
        names = []
        scores = []
        errors = []
        
        for name, score_info in model_scores.items():
            if score_info['model'] is not None:
                names.append(name)
                scores.append(score_info['mean_score'])
                errors.append(score_info['std_score'])
        
        if not names:
            return
        
        plt.figure(figsize=(12, 8))
        bars = plt.bar(names, scores, yerr=errors, capsize=5, alpha=0.7)
        
        # ç€è‰²
        colors = plt.cm.Set3(np.linspace(0, 1, len(bars)))
        for bar, color in zip(bars, colors):
            bar.set_color(color)
        
        # çªå‡ºæ˜¾ç¤ºæœ€ä½³æ¨¡å‹
        best_idx = np.argmax(scores)
        bars[best_idx].set_edgecolor('red')
        bars[best_idx].set_linewidth(3)
        
        plt.title('Model Performance Comparison', fontsize=16, fontweight='bold')
        plt.xlabel('Algorithm', fontsize=12)
        plt.ylabel('Cross-validation Accuracy', fontsize=12)
        plt.ylim(0, 1.1)
        plt.grid(True, alpha=0.3)
        
        plt.tight_layout()
        plt.savefig(f'{self.training_dir}/model_comparison.png', dpi=300, bbox_inches='tight')
        plt.close()
    
    def create_feature_analysis(self, X_features):
        """åˆ›å»ºç‰¹å¾åˆ†æå›¾è¡¨"""
        plt.figure(figsize=(15, 10))
        
        # ç‰¹å¾åˆ†å¸ƒ
        plt.subplot(2, 2, 1)
        feature_means = np.mean(X_features, axis=0)
        plt.hist(feature_means, bins=50, alpha=0.7, color='skyblue', edgecolor='black')
        plt.title('Feature Mean Distribution', fontsize=14)
        plt.xlabel('Feature Value')
        plt.ylabel('Frequency')
        
        # Feature variance
        plt.subplot(2, 2, 2)
        feature_vars = np.var(X_features, axis=0)
        plt.hist(feature_vars, bins=50, alpha=0.7, color='lightcoral', edgecolor='black')
        plt.title('Feature Variance Distribution', fontsize=14)
        plt.xlabel('Feature Value')
        plt.ylabel('Frequency')
        
        # PCA visualization
        plt.subplot(2, 2, 3)
        if X_features.shape[1] > 2:
            pca = PCA(n_components=2)
            X_pca = pca.fit_transform(X_features)
            plt.scatter(X_pca[:, 0], X_pca[:, 1], alpha=0.7)
            plt.title('PCA 2D Visualization', fontsize=14)
            plt.xlabel('First Principal Component')
            plt.ylabel('Second Principal Component')
        
        # Feature importance
        plt.subplot(2, 2, 4)
        if hasattr(self.model, 'feature_importances_'):
            importances = self.model.feature_importances_
            indices = np.argsort(importances)[-20:]  # Show top 20 important features
            plt.barh(range(20), importances[indices])
            plt.yticks(range(20), [f'Feature_{i}' for i in indices])
            plt.title('Feature Importance', fontsize=14)
            plt.xlabel('Importance')
        
        plt.tight_layout()
        plt.savefig(f'{self.training_dir}/feature_analysis.png', dpi=300, bbox_inches='tight')
        plt.close()
    
    def create_training_summary(self, y_true, y_pred):
        """åˆ›å»ºè®­ç»ƒæ‘˜è¦"""
        # ç”Ÿæˆè¯¦ç»†æŠ¥å‘Š
        report = classification_report(y_true, y_pred, target_names=self.class_names, 
                                     digits=4, zero_division=0)
        
        # åˆ›å»ºæ‘˜è¦å›¾è¡¨
        fig, ax = plt.subplots(1, 1, figsize=(12, 8))
        ax.axis('off')
        
        # Text content
        summary_text = f"""
ChladniVision Optimized Training Summary
{'='*50}

Model Information:
â€¢ Best Algorithm: {self.model_info.get('best_model', 'Unknown')}
â€¢ Validation Accuracy: {self.model_info.get('best_score', 0):.4f}
â€¢ Number of Classes: {len(self.class_names)}
â€¢ Total Samples: {len(y_true)}
â€¢ Ensemble Learning: {'Yes' if self.model_info.get('is_ensemble', False) else 'No'}

Performance Metrics:
â€¢ Training Accuracy: {accuracy_score(y_true, y_pred):.4f}
â€¢ Model Type: {type(self.model).__name__}

Feature Configuration:
â€¢ Feature Extractor: OptimizedFeatureExtractor
â€¢ Feature Dimension: {self.feature_extractor.n_features}
â€¢ PCA Dimensionality: {self.feature_extractor.pca.n_components_ if hasattr(self.feature_extractor, 'pca') and self.feature_extractor.pca else 'N/A'}

Training Time: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
        """
        
        ax.text(0.1, 0.9, summary_text, transform=ax.transAxes, 
               fontsize=12, verticalalignment='top', fontfamily='monospace')
        
        plt.tight_layout()
        plt.savefig(f'{self.training_dir}/training_summary.png', dpi=300, bbox_inches='tight')
        plt.close()
        
        # Save text report
        with open(f'{self.reports_dir}/classification_report.txt', 'w', encoding='utf-8') as f:
            f.write("ChladniVision Optimized Detailed Classification Report\n")
            f.write("="*60 + "\n\n")
            f.write(summary_text)
            f.write("\n\nDetailed Classification Report:\n")
            f.write(report)
    
    def save_model(self, model_path):
        """ä¿å­˜æ¨¡å‹"""
        model_data = {
            'model': self.model,
            'feature_extractor': self.feature_extractor,
            'class_names': self.class_names,
            'model_info': self.model_info,
            'is_trained': self.is_trained
        }
        
        joblib.dump(model_data, model_path)
    
    def load_model(self, model_path):
        """åŠ è½½æ¨¡å‹"""
        if not os.path.exists(model_path):
            print(f"âŒ æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_path}")
            return False
        
        try:
            model_data = joblib.load(model_path)
            
            self.model = model_data['model']
            self.feature_extractor = model_data['feature_extractor']
            self.class_names = model_data['class_names']
            self.model_info = model_data.get('model_info', {})
            self.is_trained = model_data['is_trained']
            
            print("âœ… æ¨¡å‹åŠ è½½æˆåŠŸ")
            print(f"   æ¨¡å‹ç±»å‹: {self.model_info.get('best_model', 'Unknown')}")
            print(f"   æ”¯æŒç±»åˆ«: {len(self.class_names)}")
            return True
            
        except Exception as e:
            print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            return False
    
    def interactive_mode(self):
        """äº¤äº’å¼æ¨¡å¼"""
        print("\nğŸ¯ äº¤äº’å¼æ¨¡å¼")
        print("   ğŸ“® è¾“å…¥å›¾åƒè·¯å¾„è¿›è¡Œé¢„æµ‹ï¼Œæˆ–ä½¿ç”¨ä»¥ä¸‹å¿«æ·å‘½ä»¤:")
        print("   ğŸ² 'example' - ä½¿ç”¨ç¤ºä¾‹å›¾åƒè‡ªåŠ¨æ¼”ç¤º")
        print("   ğŸ“Š 'show' - å±•ç¤ºç”Ÿæˆçš„å¯è§†åŒ–ç»“æœ")
        print("   ğŸ“ 'list' - åˆ—å‡ºå¯ç”¨çš„ç¤ºä¾‹å›¾åƒ")
        print("   ğŸª 'demo' - å®Œæ•´åŠŸèƒ½æ¼”ç¤º")
        print("   ğŸšª 'quit' - é€€å‡ºç¨‹åº")
        
        # è·å–ç¤ºä¾‹å›¾åƒåˆ—è¡¨
        example_images = self._get_example_images()
        
        while True:
            user_input = input("\nğŸ“· è¯·è¾“å…¥å‘½ä»¤æˆ–å›¾åƒè·¯å¾„: ").strip()
            
            if user_input.lower() == 'quit':
                print("ğŸ‘‹ é€€å‡ºäº¤äº’æ¨¡å¼")
                break
            
            elif user_input.lower() == 'example':
                self._run_example_prediction()
            
            elif user_input.lower() == 'show':
                self._show_visualization_results()
            
            elif user_input.lower() == 'list':
                self._list_example_images(example_images)
            
            elif user_input.lower() == 'demo':
                self._run_full_demo()
            
            elif os.path.exists(user_input):
                self.predict(user_input, save_result=True)
            else:
                print("âŒ æ–‡ä»¶ä¸å­˜åœ¨æˆ–å‘½ä»¤æ— æ•ˆ")
                print("ğŸ’¡ è¾“å…¥ 'list' æŸ¥çœ‹å¯ç”¨ç¤ºä¾‹ï¼Œæˆ– 'example' è¿è¡Œç¤ºä¾‹é¢„æµ‹")
    
    def _get_example_images(self):
        """è·å–ç¤ºä¾‹å›¾åƒåˆ—è¡¨"""
        example_images = []
        data_dirs = ['data/data/', 'data/data_augmented/']
        
        for data_dir in data_dirs:
            if os.path.exists(data_dir):
                for root, dirs, files in os.walk(data_dir):
                    for file in files:
                        if file.endswith(('.png', '.jpg', '.jpeg')):
                            example_images.append(os.path.join(root, file))
                            if len(example_images) >= 10:  # é™åˆ¶æ•°é‡
                                break
                    if len(example_images) >= 10:
                        break
                if len(example_images) >= 10:
                    break
        
        return example_images
    
    def _list_example_images(self, example_images):
        """åˆ—å‡ºç¤ºä¾‹å›¾åƒ"""
        print("\nğŸ“ å¯ç”¨çš„ç¤ºä¾‹å›¾åƒ:")
        for i, img_path in enumerate(example_images[:10], 1):
            filename = os.path.basename(img_path)
            # ä»è·¯å¾„ä¸­æå–é¢‘ç‡ä¿¡æ¯
            freq = "Unknown"
            for f in ['600Hz', '700Hz', '800Hz', '900Hz', '1100Hz']:
                if f in img_path:
                    freq = f
                    break
            print(f"   {i:2d}. {filename} ({freq})")
        
        if len(example_images) > 10:
            print(f"   ... è¿˜æœ‰ {len(example_images) - 10} ä¸ªå›¾åƒ")
        
        print(f"\nğŸ’¡ ä½¿ç”¨æ–¹æ³•:")
        print(f"   - è¾“å…¥å®Œæ•´è·¯å¾„: {example_images[0]}")
        print(f"   - æˆ–è¾“å…¥ 'example' è‡ªåŠ¨é€‰æ‹©ç¤ºä¾‹")
    
    def _run_example_prediction(self):
        """è¿è¡Œç¤ºä¾‹é¢„æµ‹"""
        example_images = self._get_example_images()
        if not example_images:
            print("âŒ æœªæ‰¾åˆ°ç¤ºä¾‹å›¾åƒ")
            return
        
        # éšæœºé€‰æ‹©ä¸€ä¸ªç¤ºä¾‹å›¾åƒ
        import random
        selected_image = random.choice(example_images[:5])  # ä»å‰5ä¸ªä¸­é€‰æ‹©
        filename = os.path.basename(selected_image)
        
        print(f"\nğŸ² ä½¿ç”¨ç¤ºä¾‹å›¾åƒ: {filename}")
        self.predict(selected_image, save_result=True)
    
    def _show_visualization_results(self):
        """å±•ç¤ºå¯è§†åŒ–ç»“æœ"""
        print(f"\nğŸ“Š æŸ¥çœ‹å¯è§†åŒ–ç»“æœ...")
        
        output_dirs = [self.training_dir, self.predictions_dir]
        found_files = []
        
        for output_dir in output_dirs:
            if os.path.exists(output_dir):
                files = os.listdir(output_dir)
                image_files = [f for f in files if f.endswith(('.png', '.jpg', '.jpeg'))]
                found_files.extend([(output_dir, f) for f in image_files])
        
        if not found_files:
            print("âŒ æœªæ‰¾åˆ°å¯è§†åŒ–ç»“æœ")
            print("ğŸ’¡ è¯·å…ˆè¿è¡Œè®­ç»ƒæˆ–é¢„æµ‹æ¥ç”Ÿæˆå¯è§†åŒ–ç»“æœ")
            return
        
        print(f"ğŸ“¸ æ‰¾åˆ° {len(found_files)} ä¸ªå¯è§†åŒ–æ–‡ä»¶:")
        
        for i, (output_dir, filename) in enumerate(found_files[:10], 1):
            file_path = os.path.join(output_dir, filename)
            file_size = os.path.getsize(file_path)
            print(f"   {i:2d}. {filename} ({file_size:,} bytes)")
        
        # è¯¢é—®æ˜¯å¦è¦æ‰“å¼€æŸä¸ªæ–‡ä»¶
        try:
            choice = input(f"\nğŸ” è¾“å…¥æ–‡ä»¶ç¼–å·æŸ¥çœ‹è¯¦æƒ… (1-{min(10, len(found_files))}): ").strip()
            if choice.isdigit():
                idx = int(choice) - 1
                if 0 <= idx < len(found_files):
                    output_dir, filename = found_files[idx]
                    file_path = os.path.join(output_dir, filename)
                    self._show_image_details(file_path)
        except:
            pass
    
    def _show_image_details(self, image_path):
        """æ˜¾ç¤ºå›¾åƒè¯¦æƒ…"""
        try:
            import matplotlib.pyplot as plt
            import matplotlib.image as mpimg
            
            # è¯»å–å¹¶æ˜¾ç¤ºå›¾åƒ
            img = mpimg.imread(image_path)
            
            plt.figure(figsize=(12, 8))
            plt.imshow(img)
            plt.title(f"å¯è§†åŒ–ç»“æœ: {os.path.basename(image_path)}", fontsize=16, fontweight='bold')
            plt.axis('off')
            
            # æ·»åŠ æ–‡ä»¶ä¿¡æ¯
            file_size = os.path.getsize(image_path)
            info_text = f"æ–‡ä»¶å¤§å°: {file_size:,} bytes\nè·¯å¾„: {image_path}"
            plt.figtext(0.02, 0.02, info_text, fontsize=10, 
                       bbox=dict(boxstyle="round,pad=0.3", facecolor="lightgray"))
            
            plt.tight_layout()
            plt.show()
            
        except Exception as e:
            print(f"âŒ æ— æ³•æ˜¾ç¤ºå›¾åƒ: {e}")
            print(f"ğŸ’¡ æ‚¨å¯ä»¥æ‰‹åŠ¨æ‰“å¼€: {image_path}")
    
    def _run_full_demo(self):
        """è¿è¡Œå®Œæ•´åŠŸèƒ½æ¼”ç¤º"""
        print(f"\nğŸª ChladniVision å®Œæ•´åŠŸèƒ½æ¼”ç¤º")
        print("=" * 50)
        
        # 1. å±•ç¤ºç³»ç»Ÿä¿¡æ¯
        print(f"ğŸ“‹ ç³»ç»Ÿä¿¡æ¯:")
        print(f"   ğŸ§  ç‰¹å¾æå–å™¨: OptimizedFeatureExtractor")
        print(f"   ğŸ¤– æ”¯æŒç®—æ³•: RandomForest, SVM, MLP, GradientBoosting")
        print(f"   ğŸ¯ åˆ†ç±»ç±»åˆ«: {len(self.class_names) if self.class_names else 5} ä¸ª")
        print(f"   ğŸ“Š è¾“å‡ºç›®å½•: {self.output_dir}")
        
        # 2. å¦‚æœæœ‰æ¨¡å‹ï¼Œè¿›è¡Œé¢„æµ‹æ¼”ç¤º
        if self.is_trained:
            print(f"\nğŸ¯ é¢„æµ‹æ¼”ç¤º:")
            example_images = self._get_example_images()
            if example_images:
                # é€‰æ‹©ä¸åŒé¢‘ç‡çš„ç¤ºä¾‹
                demo_images = []
                freqs = ['600Hz', '700Hz', '800Hz', '900Hz', '1100Hz']
                for freq in freqs:
                    for img in example_images:
                        if freq in img:
                            demo_images.append(img)
                            break
                
                for img_path in demo_images[:3]:  # æ¼”ç¤º3ä¸ª
                    filename = os.path.basename(img_path)
                    print(f"\nğŸ“¸ é¢„æµ‹: {filename}")
                    result = self.predict(img_path, save_result=True)
                    if result:
                        print(f"   âœ… é¢„æµ‹å®Œæˆ")
        
        # 3. å±•ç¤ºå¯è§†åŒ–ç»“æœ
        print(f"\nğŸ“Š å¯è§†åŒ–å±•ç¤º:")
        self._show_visualization_results()
        
        print(f"\nğŸ‰ æ¼”ç¤ºå®Œæˆ!")
        print(f"ğŸ’¡ ç»§ç»­ä½¿ç”¨å…¶ä»–å‘½ä»¤æ¢ç´¢æ›´å¤šåŠŸèƒ½")

class EnsembleModel:
    """é›†æˆå­¦ä¹ æ¨¡å‹"""
    
    def __init__(self, models):
        self.models = models
    
    def predict(self, X):
        """é›†æˆé¢„æµ‹"""
        predictions = []
        for model in self.models:
            pred = model.predict(X)
            predictions.append(pred)
        
        # æŠ•ç¥¨å†³å®šæœ€ç»ˆç»“æœ
        predictions = np.array(predictions)
        result = []
        for i in range(predictions.shape[1]):
            votes = predictions[:, i]
            # ä½¿ç”¨numpyçš„uniqueæ¥æ‰¾åˆ°æœ€å¸¸è§çš„é¢„æµ‹
            unique_votes, counts = np.unique(votes, return_counts=True)
            most_common = unique_votes[np.argmax(counts)]
            result.append(most_common)
        
        return np.array(result)
    
    def predict_proba(self, X):
        """é›†æˆæ¦‚ç‡é¢„æµ‹"""
        all_probs = []
        for model in self.models:
            if hasattr(model, 'predict_proba'):
                probs = model.predict_proba(X)
                all_probs.append(probs)
        
        if all_probs:
            # å¹³å‡æ¦‚ç‡
            avg_probs = np.mean(all_probs, axis=0)
            return avg_probs
        else:
            # å¦‚æœæ²¡æœ‰æ¦‚ç‡é¢„æµ‹ï¼Œè¿”å›ç®€å•æŠ•ç¥¨ç»“æœ
            predictions = self.predict(X)
            n_classes = len(np.unique(predictions))
            result = np.zeros((len(predictions), n_classes))
            for i, pred in enumerate(predictions):
                result[i, pred] = 1.0
            return result

def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='ChladniVision Optimized - ä¼˜åŒ–ç‰ˆç³»ç»Ÿ')
    parser.add_argument('--train', action='store_true', help='è®­ç»ƒæ¨¡å¼')
    parser.add_argument('--data_dir', type=str, help='æ•°æ®ç›®å½•è·¯å¾„')
    parser.add_argument('--predict', type=str, help='é¢„æµ‹å›¾åƒè·¯å¾„')
    parser.add_argument('--model', type=str, default='demo_optimized_model.pkl', 
                       help='æ¨¡å‹æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--interactive', action='store_true', help='äº¤äº’å¼æ¨¡å¼')
    parser.add_argument('--demo', action='store_true', help='æ¼”ç¤ºæ¨¡å¼')
    parser.add_argument('--output_dir', type=str, default='output_optimized', 
                       help='è¾“å‡ºç›®å½•')
    
    args = parser.parse_args()
    
    # åˆ›å»ºç³»ç»Ÿå®ä¾‹
    system = ChladniVisionOptimized()
    system.output_dir = args.output_dir
    system.welcome_message()
    
    if args.demo:
        # æ¼”ç¤ºæ¨¡å¼
        print("\nğŸ­ æ¼”ç¤ºæ¨¡å¼")
        print("   ä½¿ç”¨å¢å¼ºæ•°æ®é›†è¿›è¡Œå¿«é€Ÿæ¼”ç¤º...")
        
        # è®­ç»ƒæ¼”ç¤ºæ¨¡å‹
        success = system.train('data/data_augmented/', 'demo_optimized_model.pkl')
        if success:
            print("\nğŸ¯ æ¼”ç¤ºé¢„æµ‹:")
            # æ¼”ç¤ºé¢„æµ‹
            demo_image = 'data/data/600Hz/600hz_001.png'
            if os.path.exists(demo_image):
                system.predict(demo_image, save_result=True)
            
            # è¿›å…¥äº¤äº’æ¨¡å¼
            system.interactive_mode()
    
    elif args.train:
        # è®­ç»ƒæ¨¡å¼
        if not args.data_dir:
            print("âŒ è®­ç»ƒæ¨¡å¼éœ€è¦æŒ‡å®š --data_dir")
            return
        
        success = system.train(args.data_dir, args.model)
        if success and args.interactive:
            system.interactive_mode()
    
    elif args.predict:
        # é¢„æµ‹æ¨¡å¼
        if not system.load_model(args.model):
            return
        
        system.predict(args.predict, save_result=True)
    
    elif args.interactive:
        # äº¤äº’å¼æ¨¡å¼
        if not system.load_model(args.model):
            print("   è¯·å…ˆè®­ç»ƒæ¨¡å‹æˆ–æŒ‡å®šæ­£ç¡®çš„æ¨¡å‹è·¯å¾„")
            return
        
        system.interactive_mode()
    
    else:
        # æ˜¾ç¤ºä½¿ç”¨è¯´æ˜
        print("\nğŸ“– ä½¿ç”¨è¯´æ˜:")
        print("   1. æ¼”ç¤ºæ¨¡å¼ (å¿«é€Ÿä½“éªŒ):")
        print("      python chladni_vision_optimized.py --demo")
        print("")
        print("   2. è®­ç»ƒæ¨¡å‹:")
        print("      python chladni_vision_optimized.py --train --data_dir data/data_augmented/")
        print("")
        print("   3. é¢„æµ‹å›¾åƒ:")
        print("      python chladni_vision_optimized.py --predict image.png")
        print("")
        print("   4. äº¤äº’å¼æ¨¡å¼:")
        print("      python chladni_vision_optimized.py --interactive")
        print("")
        print("   5. è®­ç»ƒåè¿›å…¥äº¤äº’æ¨¡å¼:")
        print("      python chladni_vision_optimized.py --train --data_dir data/data_augmented/ --interactive")
        print("")
        print("ğŸ”§ è¾“å‡ºæ–‡ä»¶:")
        print("   - output_optimized/confusion_matrix.png")
        print("   - output_optimized/model_comparison.png")
        print("   - output_optimized/feature_analysis.png")
        print("   - output_optimized/training_summary.png")
        print("   - output_optimized/prediction_*.png")
        print("   - output_optimized/classification_report.txt")

if __name__ == "__main__":
    main()