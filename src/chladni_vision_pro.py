#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ChladniVision Pro - ä¼˜åŒ–ç‰ˆç³»ç»Ÿ
å¢å¼ºç‰¹å¾æå–ã€æ”¹è¿›å¯è§†åŒ–ã€ä¼˜åŒ–ç®—æ³•é€‰æ‹©
"""

import os
import sys
import cv2
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV
from sklearn.neighbors import KNeighborsClassifier
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.svm import SVC
from sklearn.neural_network import MLPClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
from sklearn.preprocessing import StandardScaler, RobustScaler
from sklearn.decomposition import PCA
from sklearn.cluster import KMeans
import joblib
from tqdm import tqdm
from datetime import datetime
import argparse
from collections import Counter
import warnings
import pandas as pd
from pathlib import Path
warnings.filterwarnings('ignore')

# è®¾ç½®æ›´ç¾è§‚çš„ç»˜å›¾æ ·å¼
plt.style.use('seaborn-v0_8')
sns.set_palette("husl")

# Windowsç³»ç»Ÿç¼–ç ä¿®å¤
def safe_print(text):
    """å®Œå…¨å…¼å®¹Windowsçš„å®‰å…¨æ‰“å°å‡½æ•°"""
    try:
        # ç§»é™¤æ‰€æœ‰emojiå’Œç‰¹æ®Šå­—ç¬¦
        clean_text = text
        emoji_replacements = {
            'ğŸµ': '[éŸ³ä¹]', 'ğŸš€': '[å¯åŠ¨]', 'ğŸ“': '[æ–‡ä»¶å¤¹]', 'âŒ': '[å¤±è´¥]', 'âœ…': '[æˆåŠŸ]',
            'ğŸ¤–': '[AI]', 'ğŸ”': '[æœç´¢]', 'ğŸ“Š': '[å›¾è¡¨]', 'ğŸ¯': '[ç›®æ ‡]', 'ğŸ²': '[æ¦‚ç‡]',
            'ğŸ“ˆ': '[ä¸Šå‡]', 'ğŸ’¾': '[ä¿å­˜]', 'â±ï¸': '[æ—¶é—´]', 'ğŸ‰': '[å®Œæˆ]', 'ğŸ‘‹': '[å†è§]',
            'ğŸ“·': '[ç›¸æœº]', 'ğŸ“–': '[è¯´æ˜]', 'ğŸ”§': '[è®¾ç½®]', 'â­': '[æ˜Ÿçº§]', 'ğŸ”¬': '[ç§‘å­¦]',
            'ğŸ¨': '[è‰ºæœ¯]', 'ğŸŒŸ': '[äº®ç‚¹]', 'ğŸ’¡': '[æç¤º]', 'ğŸª': '[æ¼”ç¤º]', 'ğŸ†': '[å¥–æ¯]',
            'ğŸ“‹': '[åˆ—è¡¨]', 'ğŸ”„': '[äº¤äº’]', 'âœ¨': '[é—ªäº®]', 'ğŸ””': '[é€šçŸ¥]', 'ğŸ“±': '[æ‰‹æœº]',
            'ğŸ’»': '[ç”µè„‘]', 'ğŸŒ': '[ç½‘ç»œ]', 'ğŸ®': '[æ¸¸æˆ]', 'ğŸ': '[ç¤¼ç‰©]', 'ğŸŠ': '[æ´¾å¯¹]'
        }
        
        for emoji, replacement in emoji_replacements.items():
            clean_text = clean_text.replace(emoji, replacement)
        
        print(clean_text)
    except Exception:
        # å¦‚æœä»æœ‰é—®é¢˜ï¼Œä½¿ç”¨æœ€åŸºç¡€çš„ASCIIå­—ç¬¦
        try:
            ascii_text = text.encode('ascii', 'ignore').decode('ascii')
            print(ascii_text)
        except:
            print("è¾“å‡ºä¿¡æ¯æ— æ³•æ˜¾ç¤º")

# è®¾ç½®matplotlibå­—ä½“
plt.rcParams['font.family'] = ['DejaVu Sans', 'Arial Unicode MS', 'SimHei']
plt.rcParams['axes.unicode_minus'] = False
plt.rcParams['figure.titlesize'] = 16
plt.rcParams['axes.titlesize'] = 14
plt.rcParams['axes.labelsize'] = 12
plt.rcParams['xtick.labelsize'] = 10
plt.rcParams['ytick.labelsize'] = 10
plt.rcParams['legend.fontsize'] = 10

class ChladniVisionPro:
    """
    ChladniVision Pro - ä¼˜åŒ–ç‰ˆç³»ç»Ÿ
    """
    
    def __init__(self):
        """åˆå§‹åŒ–ç³»ç»Ÿ"""
        self.model = None
        self.scaler = RobustScaler()  # ä½¿ç”¨æ›´é²æ£’çš„ç¼©æ”¾å™¨
        self.class_names = []
        self.is_trained = False
        self.model_info = {}
        self.feature_extractor = None
        self.image_size = (128, 128)  # æé«˜å›¾åƒåˆ†è¾¨ç‡
        self.output_dir = "output"
        self.feature_history = []
        self.prediction_history = []
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        os.makedirs(self.output_dir, exist_ok=True)
        
        # ç‰¹å¾æå–é…ç½®
        self.feature_config = {
            'sift': True,
            'lbp': True,
            'gradient': True,
            'texture': True,
            'statistical': True,
            'frequency': True
        }
    
    def welcome_message(self):
        """æ˜¾ç¤ºæ¬¢è¿ä¿¡æ¯"""
        safe_print("=" * 70)
        safe_print("[éŸ³ä¹] ChladniVision Pro - ä¼˜åŒ–ç‰ˆç³»ç»Ÿ")
        safe_print("   å¢å¼ºç‰¹å¾æå– | æ™ºèƒ½ç®—æ³•é€‰æ‹© | ç²¾ç¾å¯è§†åŒ–")
        safe_print("=" * 70)
        safe_print("")
        safe_print("ğŸŒŸ æ ¸å¿ƒä¼˜åŒ–:")
        safe_print("   âœ… å¤šæ¨¡æ€ç‰¹å¾æå– (SIFT+LBP+æ¢¯åº¦+çº¹ç†+é¢‘åŸŸ)")
        safe_print("   âœ… æ™ºèƒ½ç®—æ³•é€‰æ‹©ä¸è¶…å‚æ•°ä¼˜åŒ–")
        safe_print("   âœ… é²æ£’ç‰¹å¾ç¼©æ”¾ä¸é™ç»´")
        safe_print("   âœ… å®æ—¶é¢„æµ‹ä¸æ‰¹é‡å¤„ç†")
        safe_print("   âœ… äº¤äº’å¼å¯è§†åŒ–ç•Œé¢")
        safe_print("   âœ… è¯¦ç»†æ€§èƒ½åˆ†æä¸æŠ¥å‘Š")
        safe_print("")
    
    def load_dataset(self, data_dir):
        """åŠ è½½æ•°æ®é›†"""
        safe_print(f"[æ–‡ä»¶å¤¹] åŠ è½½æ•°æ®é›†: {data_dir}")
        
        if not os.path.exists(data_dir):
            safe_print("[å¤±è´¥] æ•°æ®ç›®å½•ä¸å­˜åœ¨")
            return None, None, None
        
        images = []
        labels = []
        paths = []
        
        # æ£€æŸ¥æ•°æ®é›†ç»“æ„
        if 'train' in os.listdir(data_dir) and 'test' in os.listdir(data_dir):
            # train/test ç»“æ„
            for split in ['train', 'test']:
                split_dir = os.path.join(data_dir, split)
                if not os.path.exists(split_dir):
                    continue
                
                safe_print(f"   å¤„ç† {split} æ•°æ®...")
                freq_dirs = [d for d in os.listdir(split_dir) 
                           if os.path.isdir(os.path.join(split_dir, d))]
                
                for freq in freq_dirs:
                    freq_dir = os.path.join(split_dir, freq)
                    self._load_images_from_dir(freq_dir, freq, images, labels, paths)
        else:
            # é¢‘ç‡ç›®å½•ç»“æ„
            safe_print("   å¤„ç†é¢‘ç‡ç›®å½•...")
            freq_dirs = [d for d in os.listdir(data_dir) 
                       if os.path.isdir(os.path.join(data_dir, d))]
            
            for freq in freq_dirs:
                freq_dir = os.path.join(data_dir, freq)
                self._load_images_from_dir(freq_dir, freq, images, labels, paths)
        
        if not images:
            safe_print("[å¤±è´¥] æœªæ‰¾åˆ°å›¾åƒæ–‡ä»¶")
            return None, None, None
        
        safe_print(f"   [æˆåŠŸ] åŠ è½½ {len(images)} å¼ å›¾åƒ")
        class_counts = Counter(labels)
        safe_print("   ç±»åˆ«åˆ†å¸ƒ:")
        for class_name, count in class_counts.items():
            safe_print(f"      {class_name}: {count} å¼ ")
        
        self.class_names = sorted(list(set(labels)))
        return np.array(images), np.array(labels), paths
    
    def _load_images_from_dir(self, dir_path, label, images, labels, paths):
        """ä»ç›®å½•åŠ è½½å›¾åƒ"""
        if not os.path.exists(dir_path):
            return
        
        image_files = [f for f in os.listdir(dir_path) 
                     if f.lower().endswith(('.png', '.jpg', '.jpeg'))]
        
        for filename in tqdm(image_files, desc=f"      {label}", leave=False):
            image_path = os.path.join(dir_path, filename)
            
            try:
                # è¯»å–å’Œé¢„å¤„ç†å›¾åƒ
                image = cv2.imread(image_path)
                if image is None:
                    continue
                
                # è½¬æ¢ä¸ºç°åº¦
                gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
                
                # è°ƒæ•´å°ºå¯¸
                resized = cv2.resize(gray, self.image_size, interpolation=cv2.INTER_AREA)
                
                # è‡ªé€‚åº”ç›´æ–¹å›¾å‡è¡¡åŒ–
                clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
                enhanced = clahe.apply(resized)
                
                # å½’ä¸€åŒ–
                normalized = enhanced.astype(np.float32) / 255.0
                
                images.append(normalized)
                labels.append(label)
                paths.append(image_path)
                
            except Exception as e:
                continue
    
    def extract_sift_features(self, image):
        """æå–SIFTç‰¹å¾"""
        try:
            # è½¬æ¢ä¸ºuint8
            img_uint8 = (image * 255).astype(np.uint8)
            
            # åˆ›å»ºSIFTæ£€æµ‹å™¨
            sift = cv2.SIFT_create(nfeatures=50, nOctaveLayers=3, 
                                   contrastThreshold=0.03, edgeThreshold=10)
            
            # æ£€æµ‹å…³é”®ç‚¹å’Œè®¡ç®—æè¿°ç¬¦
            keypoints, descriptors = sift.detectAndCompute(img_uint8, None)
            
            if descriptors is not None and len(descriptors) > 0:
                # ä½¿ç”¨K-meansèšç±»ç”Ÿæˆè§†è§‰è¯è¢‹
                if len(descriptors) >= 10:
                    kmeans = KMeans(n_clusters=min(10, len(descriptors)), random_state=42)
                    kmeans.fit(descriptors)
                    
                    # è®¡ç®—ç›´æ–¹å›¾
                    hist = np.zeros(10)
                    for d in descriptors:
                        cluster_idx = kmeans.predict([d])[0]
                        hist[cluster_idx] += 1
                    
                    # å½’ä¸€åŒ–ç›´æ–¹å›¾
                    hist = hist / (np.sum(hist) + 1e-7)
                    return hist
            
            return np.zeros(10)
            
        except Exception:
            return np.zeros(10)
    
    def extract_lbp_features(self, image):
        """æå–LBP (å±€éƒ¨äºŒå€¼æ¨¡å¼) ç‰¹å¾"""
        try:
            img_uint8 = (image * 255).astype(np.uint8)
            
            # LBPå‚æ•°
            radius = 3
            n_points = 8 * radius
            
            # è®¡ç®—LBP
            lbp = np.zeros_like(img_uint8)
            for i in range(radius, img_uint8.shape[0] - radius):
                for j in range(radius, img_uint8.shape[1] - radius):
                    center = img_uint8[i, j]
                    code = 0
                    for k in range(n_points):
                        angle = 2 * np.pi * k / n_points
                        x = i + radius * np.cos(angle)
                        y = j + radius * np.sin(angle)
                        
                        if 0 <= x < img_uint8.shape[0] and 0 <= y < img_uint8.shape[1]:
                            if img_uint8[int(x), int(y)] >= center:
                                code += 2**k
                    
                    lbp[i, j] = code
            
            # è®¡ç®—LBPç›´æ–¹å›¾
            hist, _ = np.histogram(lbp.ravel(), bins=256, range=(0, 256))
            hist = hist.astype(np.float32)
            hist = hist / (np.sum(hist) + 1e-7)
            
            # é™ç»´åˆ°32ç»´
            return hist[::8]  # æ¯8ä¸ªbinå–ä¸€ä¸ª
            
        except Exception:
            return np.zeros(32)
    
    def extract_gradient_features(self, image):
        """æå–æ¢¯åº¦ç‰¹å¾"""
        try:
            # Sobelæ¢¯åº¦
            sobel_x = cv2.Sobel(image, cv2.CV_64F, 1, 0, ksize=3)
            sobel_y = cv2.Sobel(image, cv2.CV_64F, 0, 1, ksize=3)
            
            # æ¢¯åº¦å¹…å€¼å’Œæ–¹å‘
            gradient_mag = np.sqrt(sobel_x**2 + sobel_y**2)
            gradient_dir = np.arctan2(sobel_y, sobel_x)
            
            # ç»Ÿè®¡ç‰¹å¾
            features = [
                np.mean(gradient_mag),
                np.std(gradient_mag),
                np.max(gradient_mag),
                np.min(gradient_mag),
                np.mean(gradient_dir),
                np.std(gradient_dir),
                np.percentile(gradient_mag, 25),
                np.percentile(gradient_mag, 75),
                np.percentile(gradient_mag, 90),
                np.percentile(gradient_mag, 95)
            ]
            
            # æ¢¯åº¦ç›´æ–¹å›¾ (8ä¸ªæ–¹å‘)
            hist, _ = np.histogram(gradient_dir.ravel(), bins=8, range=(-np.pi, np.pi))
            hist = hist.astype(np.float32)
            hist = hist / (np.sum(hist) + 1e-7)
            
            return np.concatenate([features, hist])
            
        except Exception:
            return np.zeros(18)
    
    def extract_texture_features(self, image):
        """æå–çº¹ç†ç‰¹å¾"""
        try:
            img_uint8 = (image * 255).astype(np.uint8)
            
            # è®¡ç®—ç°åº¦å…±ç”ŸçŸ©é˜µç‰¹å¾
            # ç®€åŒ–çš„çº¹ç†ç‰¹å¾
            features = []
            
            # ä¸åŒæ–¹å‘çš„çº¹ç†ç‰¹å¾
            angles = [0, 45, 90, 135]
            for angle in angles:
                # è®¡ç®—ç‰¹å®šæ–¹å‘çš„æ¢¯åº¦
                rad = np.deg2rad(angle)
                kernel_x = np.cos(rad)
                kernel_y = np.sin(rad)
                
                gradient = cv2.filter2D(img_uint8, -1, np.array([[kernel_x, kernel_y]]))
                features.extend([
                    np.mean(gradient),
                    np.std(gradient),
                    np.max(gradient),
                    np.min(gradient)
                ])
            
            return np.array(features)
            
        except Exception:
            return np.zeros(16)
    
    def extract_statistical_features(self, image):
        """æå–ç»Ÿè®¡ç‰¹å¾"""
        try:
            features = []
            
            # åŸºæœ¬ç»Ÿè®¡
            features.extend([
                np.mean(image),
                np.std(image),
                np.var(image),
                np.min(image),
                np.max(image),
                np.median(image),
                np.percentile(image, 25),
                np.percentile(image, 75)
            ])
            
            # é«˜é˜¶ç»Ÿè®¡
            features.extend([
                np.mean((image - np.mean(image))**3),  # ååº¦
                np.mean((image - np.mean(image))**4),  # å³°åº¦
                np.sum(image > np.mean(image)) / image.size,  # è¶…è¿‡å‡å€¼çš„åƒç´ æ¯”ä¾‹
                np.sum(image < np.mean(image)) / image.size   # ä½äºå‡å€¼çš„åƒç´ æ¯”ä¾‹
            ])
            
            # åˆ†ä½æ•°ç‰¹å¾
            for p in [10, 20, 30, 40, 60, 70, 80, 90]:
                features.append(np.percentile(image, p))
            
            return np.array(features)
            
        except Exception:
            return np.zeros(22)
    
    def extract_frequency_features(self, image):
        """æå–é¢‘åŸŸç‰¹å¾"""
        try:
            # å‚…é‡Œå¶å˜æ¢
            f_transform = np.fft.fft2(image)
            f_shift = np.fft.fftshift(f_transform)
            magnitude_spectrum = np.abs(f_shift)
            
            # é¢‘åŸŸç»Ÿè®¡ç‰¹å¾
            features = []
            
            # ä¸åŒé¢‘ç‡ç¯çš„èƒ½é‡
            h, w = magnitude_spectrum.shape
            center_h, center_w = h // 2, w // 2
            
            radii = [5, 10, 15, 20, 25, 30]
            for radius in radii:
                if radius < min(center_h, center_w):
                    # åˆ›å»ºç¯å½¢æ©ç 
                    y, x = np.ogrid[:h, :w]
                    mask = (x - center_w)**2 + (y - center_h)**2 <= radius**2
                    
                    if radius > 5:
                        inner_mask = (x - center_w)**2 + (y - center_h)**2 <= (radius-5)**2
                        mask = mask & ~inner_mask
                    
                    energy = np.sum(magnitude_spectrum[mask])
                    features.append(energy)
            
            # æ€»èƒ½é‡å’Œèƒ½é‡åˆ†å¸ƒ
            total_energy = np.sum(magnitude_spectrum)
            features.append(total_energy)
            
            if total_energy > 0:
                features.extend([
                    np.sum(magnitude_spectrum[:center_h, :center_w]) / total_energy,  # å·¦ä¸Šè±¡é™
                    np.sum(magnitude_spectrum[:center_h, center_w:]) / total_energy,  # å³ä¸Šè±¡é™
                    np.sum(magnitude_spectrum[center_h:, :center_w]) / total_energy,  # å·¦ä¸‹è±¡é™
                    np.sum(magnitude_spectrum[center_h:, center_w:]) / total_energy   # å³ä¸‹è±¡é™
                ])
            else:
                features.extend([0, 0, 0, 0])
            
            return np.array(features)
            
        except Exception:
            return np.zeros(11)
    
    def extract_features(self, images):
        """æå–ç»¼åˆç‰¹å¾"""
        safe_print("[æœç´¢] æå–å¤šæ¨¡æ€å›¾åƒç‰¹å¾...")
        
        features = []
        
        for i, image in enumerate(tqdm(images, desc="   æå–ç‰¹å¾")):
            try:
                feature_vector = []
                
                # æå–å„ç§ç‰¹å¾
                if self.feature_config['sift']:
                    sift_features = self.extract_sift_features(image)
                    feature_vector.extend(sift_features)
                
                if self.feature_config['lbp']:
                    lbp_features = self.extract_lbp_features(image)
                    feature_vector.extend(lbp_features)
                
                if self.feature_config['gradient']:
                    gradient_features = self.extract_gradient_features(image)
                    feature_vector.extend(gradient_features)
                
                if self.feature_config['texture']:
                    texture_features = self.extract_texture_features(image)
                    feature_vector.extend(texture_features)
                
                if self.feature_config['statistical']:
                    statistical_features = self.extract_statistical_features(image)
                    feature_vector.extend(statistical_features)
                
                if self.feature_config['frequency']:
                    frequency_features = self.extract_frequency_features(image)
                    feature_vector.extend(frequency_features)
                
                # æ¸…ç†å¼‚å¸¸å€¼
                feature_vector = np.nan_to_num(feature_vector, nan=0.0)
                features.append(feature_vector)
                
            except Exception as e:
                # ä½¿ç”¨é›¶å‘é‡
                total_features = sum([
                    10 if self.feature_config['sift'] else 0,
                    32 if self.feature_config['lbp'] else 0,
                    18 if self.feature_config['gradient'] else 0,
                    16 if self.feature_config['texture'] else 0,
                    22 if self.feature_config['statistical'] else 0,
                    11 if self.feature_config['frequency'] else 0
                ])
                dummy_feature = np.zeros(total_features)
                features.append(dummy_feature)
        
        features = np.array(features)
        features = np.nan_to_num(features, nan=0.0)
        
        safe_print(f"   [æˆåŠŸ] ç‰¹å¾ç»´åº¦: {features.shape[1]}")
        
        # è®°å½•ç‰¹å¾ç»Ÿè®¡ä¿¡æ¯
        self.feature_history.append({
            'timestamp': datetime.now(),
            'feature_shape': features.shape,
            'feature_config': self.feature_config.copy()
        })
        
        return features
    
    def optimize_features(self, X_features):
        """ä¼˜åŒ–ç‰¹å¾å¤„ç†"""
        safe_print("[ğŸ”§] ä¼˜åŒ–ç‰¹å¾å¤„ç†...")
        
        # ç‰¹å¾æ ‡å‡†åŒ–
        X_scaled = self.scaler.fit_transform(X_features)
        
        # PCAé™ç»´ (ä¿ç•™95%çš„æ–¹å·®)
        pca = PCA(n_components=0.95, random_state=42)
        X_pca = pca.fit_transform(X_scaled)
        
        safe_print(f"   [æˆåŠŸ] PCAé™ç»´: {X_scaled.shape[1]} â†’ {X_pca.shape[1]}")
        
        return X_pca, pca
    
    def optimize_hyperparameters(self, X_train, y_train, model_name):
        """ä¼˜åŒ–è¶…å‚æ•°"""
        safe_print(f"[ğŸ”§] ä¼˜åŒ– {model_name} è¶…å‚æ•°...")
        
        if model_name == 'KNN':
            param_grid = {
                'n_neighbors': [3, 5, 7, 9, 11],
                'weights': ['uniform', 'distance'],
                'metric': ['euclidean', 'manhattan', 'minkowski']
            }
            base_model = KNeighborsClassifier()
            
        elif model_name == 'RandomForest':
            param_grid = {
                'n_estimators': [50, 100, 200],
                'max_depth': [None, 10, 20, 30],
                'min_samples_split': [2, 5, 10],
                'min_samples_leaf': [1, 2, 4]
            }
            base_model = RandomForestClassifier(random_state=42)
            
        elif model_name == 'SVM':
            param_grid = {
                'C': [0.1, 1, 10, 100],
                'gamma': ['scale', 'auto', 0.001, 0.01, 0.1],
                'kernel': ['rbf', 'poly', 'sigmoid']
            }
            base_model = SVC(random_state=42)
            
        elif model_name == 'MLP':
            param_grid = {
                'hidden_layer_sizes': [(50,), (100,), (50, 50), (100, 50)],
                'activation': ['relu', 'tanh'],
                'alpha': [0.0001, 0.001, 0.01],
                'learning_rate': ['constant', 'adaptive']
            }
            base_model = MLPClassifier(random_state=42, max_iter=1000)
            
        else:
            return None
        
        # ç½‘æ ¼æœç´¢
        grid_search = GridSearchCV(
            base_model, param_grid, cv=5, scoring='accuracy', 
            n_jobs=-1, verbose=0
        )
        
        grid_search.fit(X_train, y_train)
        
        safe_print(f"   [æˆåŠŸ] æœ€ä½³å‚æ•°: {grid_search.best_params_}")
        safe_print(f"   [æˆåŠŸ] æœ€ä½³å¾—åˆ†: {grid_search.best_score_:.4f}")
        
        return grid_search.best_estimator_
    
    def select_best_model(self, X_train, y_train):
        """é€‰æ‹©æœ€ä½³æ¨¡å‹"""
        safe_print("[ğŸ¤–] æ™ºèƒ½ç®—æ³•é€‰æ‹©ä¸ä¼˜åŒ–...")
        
        models = {
            'KNN': KNeighborsClassifier(),
            'RandomForest': RandomForestClassifier(random_state=42),
            'SVM': SVC(random_state=42, probability=True),
            'MLP': MLPClassifier(random_state=42, max_iter=1000),
            'GradientBoosting': GradientBoostingClassifier(random_state=42)
        }
        
        best_model = None
        best_score = 0
        best_name = ""
        model_scores = {}
        
        for name, base_model in models.items():
            try:
                # ä¼˜åŒ–è¶…å‚æ•°
                optimized_model = self.optimize_hyperparameters(X_train, y_train, name)
                
                if optimized_model is None:
                    # å¦‚æœä¼˜åŒ–å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤æ¨¡å‹
                    optimized_model = base_model
                
                # äº¤å‰éªŒè¯
                cv_scores = cross_val_score(optimized_model, X_train, y_train, cv=5, scoring='accuracy')
                mean_score = cv_scores.mean()
                std_score = cv_scores.std()
                
                model_scores[name] = {
                    'mean_score': mean_score,
                    'std_score': std_score,
                    'model': optimized_model
                }
                
                safe_print(f"   {name}: {mean_score:.4f} (Â±{std_score:.4f})")
                
                if mean_score > best_score:
                    best_score = mean_score
                    best_model = optimized_model
                    best_name = name
                    
            except Exception as e:
                safe_print(f"   {name}: è®­ç»ƒå¤±è´¥ - {e}")
                model_scores[name] = {'mean_score': 0, 'std_score': 0, 'model': None}
        
        safe_print(f"   [ğŸŒŸ] é€‰æ‹©æ¨¡å‹: {best_name} (å‡†ç¡®ç‡: {best_score:.4f})")
        
        self.model_info = {
            'name': best_name,
            'validation_score': best_score,
            'model': best_model,
            'all_scores': model_scores
        }
        
        return best_model
    
    def train(self, data_dir, model_path='chladni_pro_model.pkl'):
        """è®­ç»ƒæ¨¡å‹"""
        safe_print(f"\n[ğŸš€] å¼€å§‹è®­ç»ƒæ¨¡å‹...")
        safe_print(f"   æ•°æ®ç›®å½•: {data_dir}")
        
        start_time = datetime.now()
        
        try:
            # åŠ è½½æ•°æ®
            X_images, y, paths = self.load_dataset(data_dir)
            if X_images is None:
                return False
            
            # æ£€æŸ¥æ•°æ®é‡æ˜¯å¦è¶³å¤Ÿ
            class_counts = Counter(y)
            min_samples = min(class_counts.values())
            
            if min_samples < 2:
                safe_print(f"[âŒ] è®­ç»ƒå¤±è´¥: æŸäº›ç±»åˆ«æ ·æœ¬å¤ªå°‘ (æœ€å°‘: {min_samples} ä¸ª)")
                return False
            
            # æå–ç‰¹å¾
            X_features = self.extract_features(X_images)
            
            # ç‰¹å¾ä¼˜åŒ–
            X_optimized, pca = self.optimize_features(X_features)
            
            # é€‰æ‹©æœ€ä½³æ¨¡å‹
            self.model = self.select_best_model(X_optimized, y)
            
            # è®­ç»ƒæœ€ç»ˆæ¨¡å‹
            safe_print("[ğŸ“Š] è®­ç»ƒæœ€ç»ˆæ¨¡å‹...")
            self.model.fit(X_optimized, y)
            
            # è¯„ä¼°æ¨¡å‹
            safe_print("[ğŸ“ˆ] è¯„ä¼°æ¨¡å‹æ€§èƒ½...")
            y_pred = self.model.predict(X_optimized)
            accuracy = accuracy_score(y, y_pred)
            
            # ä¿å­˜PCAç”¨äºé¢„æµ‹
            self.pca = pca
            
            # ç”Ÿæˆå¢å¼ºçš„å¯è§†åŒ–
            self.generate_enhanced_visualizations(y, y_pred, paths, X_optimized)
            
            # è®¾ç½®è®­ç»ƒæ ‡å¿—å¹¶ä¿å­˜æ¨¡å‹
            self.is_trained = True
            self.save_model(model_path)
            
            training_time = (datetime.now() - start_time).total_seconds()
            
            safe_print(f"\n[ğŸ‰] è®­ç»ƒå®Œæˆ!")
            safe_print(f"   [â±ï¸] è®­ç»ƒæ—¶é—´: {training_time:.2f} ç§’")
            safe_print(f"   [ğŸ“Š] è®­ç»ƒå‡†ç¡®ç‡: {accuracy:.4f}")
            safe_print(f"   [ğŸ’¾] æ¨¡å‹å·²ä¿å­˜: {model_path}")
            
            return True
            
        except Exception as e:
            safe_print(f"[âŒ] è®­ç»ƒå¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return False
    
    def generate_enhanced_visualizations(self, y_true, y_pred, paths, X_features):
        """ç”Ÿæˆå¢å¼ºçš„å¯è§†åŒ–ç»“æœ"""
        safe_print("[ğŸ¨] ç”Ÿæˆå¢å¼ºå¯è§†åŒ–ç»“æœ...")
        
        try:
            # 1. å¢å¼ºæ··æ·†çŸ©é˜µ
            self.create_enhanced_confusion_matrix(y_true, y_pred)
            
            # 2. æ¨¡å‹æ€§èƒ½å¯¹æ¯”
            self.create_model_comparison_chart()
            
            # 3. ç‰¹å¾åˆ†æ
            self.create_feature_analysis(X_features)
            
            # 4. å¢å¼ºæ ·æœ¬å±•ç¤º
            self.create_enhanced_sample_grid(paths, y_true, y_pred)
            
            # 5. è®­ç»ƒå†å²
            self.create_training_summary(y_true, y_pred)
            
            safe_print(f"   [âœ…] å¢å¼ºå¯è§†åŒ–ç»“æœå·²ä¿å­˜åˆ° {self.output_dir}/ ç›®å½•")
            
        except Exception as e:
            safe_print(f"   [âŒ] å¯è§†åŒ–ç”Ÿæˆå¤±è´¥: {e}")
    
    def create_enhanced_confusion_matrix(self, y_true, y_pred):
        """åˆ›å»ºå¢å¼ºçš„æ··æ·†çŸ©é˜µ"""
        cm = confusion_matrix(y_true, y_pred)
        
        # è®¡ç®—ç™¾åˆ†æ¯”
        cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]
        
        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))
        
        # ç»å¯¹æ•°é‡
        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
                   xticklabels=self.class_names,
                   yticklabels=self.class_names,
                   annot_kws={"size": 12}, ax=ax1)
        ax1.set_title('æ··æ·†çŸ©é˜µ (ç»å¯¹æ•°é‡)', fontsize=14, pad=20)
        ax1.set_xlabel('é¢„æµ‹ç±»åˆ«', fontsize=12)
        ax1.set_ylabel('çœŸå®ç±»åˆ«', fontsize=12)
        
        # ç™¾åˆ†æ¯”
        sns.heatmap(cm_normalized, annot=True, fmt='.2%', cmap='Reds',
                   xticklabels=self.class_names,
                   yticklabels=self.class_names,
                   annot_kws={"size": 12}, ax=ax2)
        ax2.set_title('æ··æ·†çŸ©é˜µ (ç™¾åˆ†æ¯”)', fontsize=14, pad=20)
        ax2.set_xlabel('é¢„æµ‹ç±»åˆ«', fontsize=12)
        ax2.set_ylabel('çœŸå®ç±»åˆ«', fontsize=12)
        
        plt.tight_layout()
        plt.savefig(f'{self.output_dir}/enhanced_confusion_matrix.png', dpi=300, bbox_inches='tight')
        plt.close()
    
    def create_model_comparison_chart(self):
        """åˆ›å»ºæ¨¡å‹å¯¹æ¯”å›¾è¡¨"""
        if 'all_scores' not in self.model_info:
            return
        
        model_scores = self.model_info['all_scores']
        names = []
        scores = []
        errors = []
        
        for name, score_info in model_scores.items():
            if score_info['model'] is not None:
                names.append(name)
                scores.append(score_info['mean_score'])
                errors.append(score_info['std_score'])
        
        if not names:
            return
        
        plt.figure(figsize=(12, 8))
        
        # åˆ›å»ºæŸ±çŠ¶å›¾
        bars = plt.bar(names, scores, yerr=errors, capsize=5, alpha=0.7)
        
        # ç€è‰²
        colors = plt.cm.Set3(np.linspace(0, 1, len(bars)))
        for bar, color in zip(bars, colors):
            bar.set_color(color)
        
        # æ·»åŠ æ•°å€¼æ ‡ç­¾
        for i, (score, error) in enumerate(zip(scores, errors)):
            plt.text(i, score + error + 0.01, f'{score:.3f}', 
                    ha='center', va='bottom', fontweight='bold')
        
        plt.title('æ¨¡å‹æ€§èƒ½å¯¹æ¯”', fontsize=16, pad=20)
        plt.xlabel('ç®—æ³•', fontsize=12)
        plt.ylabel('äº¤å‰éªŒè¯å‡†ç¡®ç‡', fontsize=12)
        plt.ylim(0, 1.1)
        plt.grid(True, alpha=0.3)
        
        # çªå‡ºæ˜¾ç¤ºæœ€ä½³æ¨¡å‹
        best_idx = np.argmax(scores)
        bars[best_idx].set_edgecolor('red')
        bars[best_idx].set_linewidth(3)
        
        plt.tight_layout()
        plt.savefig(f'{self.output_dir}/model_comparison.png', dpi=300, bbox_inches='tight')
        plt.close()
    
    def create_feature_analysis(self, X_features):
        """åˆ›å»ºç‰¹å¾åˆ†æå›¾è¡¨"""
        plt.figure(figsize=(15, 10))
        
        # ç‰¹å¾åˆ†å¸ƒ
        plt.subplot(2, 2, 1)
        feature_means = np.mean(X_features, axis=0)
        plt.hist(feature_means, bins=50, alpha=0.7, color='skyblue', edgecolor='black')
        plt.title('ç‰¹å¾å‡å€¼åˆ†å¸ƒ', fontsize=14)
        plt.xlabel('ç‰¹å¾å€¼')
        plt.ylabel('é¢‘æ¬¡')
        
        # ç‰¹å¾æ–¹å·®
        plt.subplot(2, 2, 2)
        feature_vars = np.var(X_features, axis=0)
        plt.hist(feature_vars, bins=50, alpha=0.7, color='lightcoral', edgecolor='black')
        plt.title('ç‰¹å¾æ–¹å·®åˆ†å¸ƒ', fontsize=14)
        plt.xlabel('ç‰¹å¾å€¼')
        plt.ylabel('é¢‘æ¬¡')
        
        # ç‰¹å¾ç›¸å…³æ€§çƒ­å›¾
        plt.subplot(2, 2, 3)
        if X_features.shape[1] > 20:
            # å¦‚æœç‰¹å¾å¤ªå¤šï¼Œåªæ˜¾ç¤ºå‰20ä¸ª
            corr_matrix = np.corrcoef(X_features[:, :20].T)
        else:
            corr_matrix = np.corrcoef(X_features.T)
        
        sns.heatmap(corr_matrix, cmap='coolwarm', center=0, 
                   square=True, cbar_kws={"shrink": 0.8})
        plt.title('ç‰¹å¾ç›¸å…³æ€§çƒ­å›¾', fontsize=14)
        
        # PCAå¯è§†åŒ–
        plt.subplot(2, 2, 4)
        if X_features.shape[1] > 2:
            from sklearn.decomposition import PCA
            pca = PCA(n_components=2)
            X_pca = pca.fit_transform(X_features)
            
            # æŒ‰ç±»åˆ«ç€è‰²
            colors = plt.cm.Set3(np.linspace(0, 1, len(self.class_names)))
            for i, class_name in enumerate(self.class_names):
                mask = np.array([self.class_names.index(label) == i for label in self.class_names * (len(X_pca) // len(self.class_names))])
                if len(mask) == len(X_pca):
                    plt.scatter(X_pca[mask, 0], X_pca[mask, 1], 
                              c=[colors[i]], label=class_name, alpha=0.7)
            
            plt.title('PCA 2Då¯è§†åŒ–', fontsize=14)
            plt.xlabel('ç¬¬ä¸€ä¸»æˆåˆ†')
            plt.ylabel('ç¬¬äºŒä¸»æˆåˆ†')
            plt.legend()
        
        plt.tight_layout()
        plt.savefig(f'{self.output_dir}/feature_analysis.png', dpi=300, bbox_inches='tight')
        plt.close()
    
    def create_enhanced_sample_grid(self, paths, y_true, y_pred):
        """åˆ›å»ºå¢å¼ºçš„æ ·æœ¬å±•ç¤ºç½‘æ ¼"""
        try:
            samples_per_class = 4
            sample_images = []
            sample_labels = []
            sample_confidences = []
            
            for class_name in self.class_names:
                class_indices = [i for i, label in enumerate(y_true) if label == class_name]
                selected_indices = class_indices[:samples_per_class]
                
                for idx in selected_indices:
                    if len(sample_images) < 16:  # æœ€å¤šæ˜¾ç¤º16å¼ 
                        sample_images.append(paths[idx])
                        correct = y_true[idx] == y_pred[idx]
                        sample_labels.append(f"{y_true[idx]}â†’{y_pred[idx]}")
                        sample_confidences.append(correct)
            
            if sample_images:
                fig, axes = plt.subplots(4, 4, figsize=(16, 16))
                axes = axes.flatten()
                
                for i, (img_path, label, correct) in enumerate(zip(sample_images, sample_labels, sample_confidences)):
                    if i < len(axes):
                        img = cv2.imread(img_path)
                        if img is not None:
                            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
                            axes[i].imshow(img)
                            
                            # æ ¹æ®æ­£ç¡®æ€§è®¾ç½®æ ‡é¢˜é¢œè‰²
                            title_color = 'green' if correct else 'red'
                            axes[i].set_title(label, fontsize=12, color=title_color, fontweight='bold')
                            axes[i].axis('off')
                            
                            # æ·»åŠ è¾¹æ¡†
                            border_color = 'green' if correct else 'red'
                            for spine in axes[i].spines.values():
                                spine.set_edgecolor(border_color)
                                spine.set_linewidth(3)
                
                # éšè—å¤šä½™çš„å­å›¾
                for i in range(len(sample_images), len(axes)):
                    axes[i].axis('off')
                
                plt.tight_layout()
                plt.savefig(f'{self.output_dir}/enhanced_sample_predictions.png', dpi=300, bbox_inches='tight')
                plt.close()
                
        except Exception as e:
            safe_print(f"   [âŒ] å¢å¼ºæ ·æœ¬ç½‘æ ¼ç”Ÿæˆå¤±è´¥: {e}")
    
    def create_training_summary(self, y_true, y_pred):
        """åˆ›å»ºè®­ç»ƒæ‘˜è¦"""
        try:
            # ç”Ÿæˆè¯¦ç»†çš„åˆ†ç±»æŠ¥å‘Š
            report = classification_report(y_true, y_pred, target_names=self.class_names, 
                                         digits=4, zero_division=0)
            
            # åˆ›å»ºæ‘˜è¦å›¾è¡¨
            fig, ax = plt.subplots(1, 1, figsize=(12, 8))
            ax.axis('off')
            
            # æ–‡æœ¬å†…å®¹
            summary_text = f"""
ChladniVision Pro è®­ç»ƒæ‘˜è¦
{'='*50}

æ¨¡å‹ä¿¡æ¯:
â€¢ æœ€ä½³ç®—æ³•: {self.model_info.get('name', 'Unknown')}
â€¢ éªŒè¯å‡†ç¡®ç‡: {self.model_info.get('validation_score', 0):.4f}
â€¢ ç±»åˆ«æ•°é‡: {len(self.class_names)}
â€¢ æ ·æœ¬æ€»æ•°: {len(y_true)}

æ€§èƒ½æŒ‡æ ‡:
â€¢ è®­ç»ƒå‡†ç¡®ç‡: {accuracy_score(y_true, y_pred):.4f}
â€¢ æ¨¡å‹ç±»å‹: {type(self.model).__name__}

ç‰¹å¾é…ç½®:
â€¢ SIFTç‰¹å¾: {'âœ…' if self.feature_config['sift'] else 'âŒ'}
â€¢ LBPç‰¹å¾: {'âœ…' if self.feature_config['lbp'] else 'âŒ'}
â€¢ æ¢¯åº¦ç‰¹å¾: {'âœ…' if self.feature_config['gradient'] else 'âŒ'}
â€¢ çº¹ç†ç‰¹å¾: {'âœ…' if self.feature_config['texture'] else 'âŒ'}
â€¢ ç»Ÿè®¡ç‰¹å¾: {'âœ…' if self.feature_config['statistical'] else 'âŒ'}
â€¢ é¢‘åŸŸç‰¹å¾: {'âœ…' if self.feature_config['frequency'] else 'âŒ'}

è®­ç»ƒæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
            """
            
            ax.text(0.1, 0.9, summary_text, transform=ax.transAxes, 
                   fontsize=12, verticalalignment='top', fontfamily='monospace')
            
            plt.tight_layout()
            plt.savefig(f'{self.output_dir}/training_summary.png', dpi=300, bbox_inches='tight')
            plt.close()
            
            # ä¿å­˜æ–‡æœ¬æŠ¥å‘Š
            with open(f'{self.output_dir}/detailed_classification_report.txt', 'w', encoding='utf-8') as f:
                f.write("ChladniVision Pro è¯¦ç»†åˆ†ç±»æŠ¥å‘Š\n")
                f.write("="*60 + "\n\n")
                f.write(summary_text)
                f.write("\n\nè¯¦ç»†åˆ†ç±»æŠ¥å‘Š:\n")
                f.write(report)
                
        except Exception as e:
            safe_print(f"   [âŒ] è®­ç»ƒæ‘˜è¦ç”Ÿæˆå¤±è´¥: {e}")
    
    def predict_and_visualize(self, image_path, save_result=True):
        """é¢„æµ‹å¹¶å¯è§†åŒ–ç»“æœ"""
        if not self.is_trained:
            safe_print("[âŒ] æ¨¡å‹å°šæœªè®­ç»ƒ")
            return None
        
        try:
            safe_print(f"[ğŸ¯] é¢„æµ‹å›¾åƒ: {image_path}")
            
            # é¢„å¤„ç†å›¾åƒ
            image = cv2.imread(image_path)
            if image is None:
                safe_print(f"[âŒ] æ— æ³•è¯»å–å›¾åƒ: {image_path}")
                return None
            
            original_image = image.copy()
            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
            resized = cv2.resize(gray, self.image_size, interpolation=cv2.INTER_AREA)
            
            # è‡ªé€‚åº”ç›´æ–¹å›¾å‡è¡¡åŒ–
            clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
            enhanced = clahe.apply(resized)
            normalized = enhanced.astype(np.float32) / 255.0
            
            # æå–ç‰¹å¾
            feature_vector = []
            if self.feature_config['sift']:
                feature_vector.extend(self.extract_sift_features(normalized))
            if self.feature_config['lbp']:
                feature_vector.extend(self.extract_lbp_features(normalized))
            if self.feature_config['gradient']:
                feature_vector.extend(self.extract_gradient_features(normalized))
            if self.feature_config['texture']:
                feature_vector.extend(self.extract_texture_features(normalized))
            if self.feature_config['statistical']:
                feature_vector.extend(self.extract_statistical_features(normalized))
            if self.feature_config['frequency']:
                feature_vector.extend(self.extract_frequency_features(normalized))
            
            feature_vector = np.nan_to_num(feature_vector, nan=0.0).reshape(1, -1)
            
            # ç‰¹å¾ä¼˜åŒ–
            feature_scaled = self.scaler.transform(feature_vector)
            feature_pca = self.pca.transform(feature_scaled)
            
            # é¢„æµ‹
            prediction = self.model.predict(feature_pca)[0]
            probabilities = self.model.predict_proba(feature_pca)[0]
            confidence = np.max(probabilities)
            
            result = {
                'predicted_class': prediction,
                'confidence': confidence,
                'probabilities': dict(zip(self.class_names, probabilities))
            }
            
            # è®°å½•é¢„æµ‹å†å²
            self.prediction_history.append({
                'timestamp': datetime.now(),
                'image_path': image_path,
                'prediction': prediction,
                'confidence': confidence,
                'probabilities': result['probabilities'].copy()
            })
            
            # æ˜¾ç¤ºç»“æœ
            safe_print(f"   [ğŸ¯] é¢„æµ‹ç»“æœ: {prediction}")
            safe_print(f"   [ğŸ²] ç½®ä¿¡åº¦: {confidence:.4f}")
            
            safe_print("   [ğŸ“Š] å„ç±»åˆ«æ¦‚ç‡:")
            sorted_probs = sorted(result['probabilities'].items(), 
                                key=lambda x: x[1], reverse=True)
            
            for class_name, prob in sorted_probs:
                bar_length = int(prob * 40)
                bar = "â–ˆ" * bar_length + "â–‘" * (40 - bar_length)
                safe_print(f"      {class_name:8s}: {prob:.4f} {bar}")
            
            # ä¿å­˜å¯è§†åŒ–ç»“æœ
            if save_result:
                self.save_enhanced_prediction_visualization(original_image, result, image_path)
            
            return result
            
        except Exception as e:
            safe_print(f"[âŒ] é¢„æµ‹å¤±è´¥: {e}")
            return None
    
    def save_enhanced_prediction_visualization(self, image, result, image_path):
        """ä¿å­˜å¢å¼ºçš„é¢„æµ‹å¯è§†åŒ–ç»“æœ"""
        try:
            fig = plt.figure(figsize=(16, 10))
            
            # åˆ›å»ºæ›´å¤æ‚çš„å¸ƒå±€
            gs = fig.add_gridspec(2, 3, height_ratios=[2, 1], width_ratios=[1, 1, 1])
            
            # åŸå§‹å›¾åƒ
            ax1 = fig.add_subplot(gs[0, 0])
            image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
            ax1.imshow(image_rgb)
            ax1.set_title('åŸå§‹å›¾åƒ', fontsize=14, fontweight='bold')
            ax1.axis('off')
            
            # é¢„æµ‹ç»“æœæ¦‚ç‡åˆ†å¸ƒ
            ax2 = fig.add_subplot(gs[0, 1])
            probs = list(result['probabilities'].values())
            classes = list(result['probabilities'].keys())
            bars = ax2.bar(classes, probs, color='skyblue', alpha=0.7)
            
            # çªå‡ºæ˜¾ç¤ºé¢„æµ‹ç»“æœ
            pred_idx = classes.index(result['predicted_class'])
            bars[pred_idx].set_color('red')
            bars[pred_idx].set_alpha(0.9)
            
            ax2.set_title('é¢„æµ‹æ¦‚ç‡åˆ†å¸ƒ', fontsize=14, fontweight='bold')
            ax2.set_ylabel('æ¦‚ç‡')
            ax2.set_ylim(0, 1)
            plt.setp(ax2.get_xticklabels(), rotation=45, ha='right')
            
            # æ·»åŠ æ¦‚ç‡å€¼æ ‡ç­¾
            for i, (class_name, prob) in enumerate(result['probabilities'].items()):
                ax2.text(i, prob + 0.01, f'{prob:.3f}', 
                        ha='center', va='bottom', fontweight='bold')
            
            # é¢„æµ‹ä¿¡æ¯é¢æ¿
            ax3 = fig.add_subplot(gs[0, 2])
            ax3.axis('off')
            
            info_text = f"""
é¢„æµ‹ç»“æœ: {result['predicted_class']}
ç½®ä¿¡åº¦: {result['confidence']:.4f}

æ¨¡å‹ä¿¡æ¯:
ç®—æ³•: {self.model_info.get('name', 'Unknown')}
éªŒè¯åˆ†æ•°: {self.model_info.get('validation_score', 0):.4f}

å›¾åƒä¿¡æ¯:
æ–‡ä»¶å: {os.path.basename(image_path)}
å°ºå¯¸: {image.shape[:2]}
é¢„æµ‹æ—¶é—´: {datetime.now().strftime('%H:%M:%S')}
            """
            
            ax3.text(0.1, 0.9, info_text, transform=ax3.transAxes, 
                    fontsize=12, verticalalignment='top', fontfamily='monospace',
                    bbox=dict(boxstyle='round', facecolor='lightblue', alpha=0.8))
            
            # ç½®ä¿¡åº¦å†å²
            ax4 = fig.add_subplot(gs[1, :])
            if len(self.prediction_history) > 1:
                confidences = [p['confidence'] for p in self.prediction_history[-10:]]
                times = [p['timestamp'].strftime('%H:%M:%S') for p in self.prediction_history[-10:]]
                
                ax4.plot(times, confidences, 'o-', color='green', linewidth=2, markersize=6)
                ax4.set_title('æœ€è¿‘10æ¬¡é¢„æµ‹çš„ç½®ä¿¡åº¦å˜åŒ–', fontsize=12, fontweight='bold')
                ax4.set_ylabel('ç½®ä¿¡åº¦')
                ax4.set_ylim(0, 1)
                plt.setp(ax4.get_xticklabels(), rotation=45, ha='right')
                ax4.grid(True, alpha=0.3)
            else:
                ax4.text(0.5, 0.5, 'æ›´å¤šé¢„æµ‹åå°†æ˜¾ç¤ºç½®ä¿¡åº¦å†å²', 
                        ha='center', va='center', transform=ax4.transAxes, fontsize=12)
                ax4.axis('off')
            
            plt.tight_layout()
            
            # ç”Ÿæˆè¾“å‡ºæ–‡ä»¶å
            image_name = os.path.splitext(os.path.basename(image_path))[0]
            output_path = f"{self.output_dir}/enhanced_prediction_{image_name}.png"
            plt.savefig(output_path, dpi=300, bbox_inches='tight')
            plt.close()
            
            safe_print(f"   [ğŸ’¾] å¢å¼ºé¢„æµ‹ç»“æœå·²ä¿å­˜: {output_path}")
            
        except Exception as e:
            safe_print(f"   [âŒ] å¢å¼ºå¯è§†åŒ–ä¿å­˜å¤±è´¥: {e}")
    
    def save_model(self, model_path):
        """ä¿å­˜æ¨¡å‹"""
        model_data = {
            'model': self.model,
            'scaler': self.scaler,
            'pca': self.pca,
            'class_names': self.class_names,
            'image_size': self.image_size,
            'model_info': self.model_info,
            'feature_config': self.feature_config,
            'is_trained': self.is_trained,
            'feature_history': self.feature_history
        }
        
        joblib.dump(model_data, model_path)
    
    def load_model(self, model_path):
        """åŠ è½½æ¨¡å‹"""
        if not os.path.exists(model_path):
            safe_print(f"[âŒ] æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_path}")
            return False
        
        try:
            model_data = joblib.load(model_path)
            
            self.model = model_data['model']
            self.scaler = model_data['scaler']
            self.pca = model_data['pca']
            self.class_names = model_data['class_names']
            self.image_size = model_data['image_size']
            self.model_info = model_data.get('model_info', {})
            self.feature_config = model_data.get('feature_config', self.feature_config)
            self.is_trained = model_data['is_trained']
            self.feature_history = model_data.get('feature_history', [])
            
            safe_print("[âœ…] æ¨¡å‹åŠ è½½æˆåŠŸ")
            safe_print(f"   æ¨¡å‹ç±»å‹: {self.model_info.get('name', 'Unknown')}")
            safe_print(f"   æ”¯æŒç±»åˆ«: {len(self.class_names)}")
            safe_print(f"   ç‰¹å¾é…ç½®: {sum(self.feature_config.values())} ç§ç‰¹å¾")
            return True
            
        except Exception as e:
            safe_print(f"[âŒ] æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            return False
    
    def interactive_mode(self):
        """äº¤äº’å¼æ¨¡å¼"""
        safe_print("\n[ğŸ¯] äº¤äº’å¼æ¨¡å¼")
        safe_print("   è¾“å…¥å›¾åƒè·¯å¾„è¿›è¡Œé¢„æµ‹ï¼Œè¾“å…¥ 'quit' é€€å‡º")
        safe_print(f"   è¾“å‡ºç›®å½•: {self.output_dir}/")
        safe_print("   å¯ç”¨å‘½ä»¤:")
        safe_print("     - 'stats': æ˜¾ç¤ºé¢„æµ‹ç»Ÿè®¡")
        safe_print("     - 'history': æ˜¾ç¤ºé¢„æµ‹å†å²")
        safe_print("     - 'batch': æ‰¹é‡é¢„æµ‹æ¨¡å¼")
        safe_print("     - 'quit': é€€å‡º")
        
        while True:
            user_input = input("\n[ğŸ“·] è¯·è¾“å…¥å‘½ä»¤æˆ–å›¾åƒè·¯å¾„: ").strip()
            
            if user_input.lower() == 'quit':
                safe_print("[ğŸ‘‹] é€€å‡ºäº¤äº’æ¨¡å¼")
                break
            
            elif user_input.lower() == 'stats':
                self.show_prediction_stats()
            
            elif user_input.lower() == 'history':
                self.show_prediction_history()
            
            elif user_input.lower() == 'batch':
                self.batch_prediction_mode()
            
            elif os.path.exists(user_input):
                self.predict_and_visualize(user_input, save_result=True)
            else:
                safe_print("[âŒ] æ–‡ä»¶ä¸å­˜åœ¨æˆ–å‘½ä»¤æ— æ•ˆï¼Œè¯·é‡æ–°è¾“å…¥")
    
    def show_prediction_stats(self):
        """æ˜¾ç¤ºé¢„æµ‹ç»Ÿè®¡"""
        if not self.prediction_history:
            safe_print("   æš‚æ— é¢„æµ‹è®°å½•")
            return
        
        safe_print("\n[ğŸ“Š] é¢„æµ‹ç»Ÿè®¡:")
        safe_print(f"   æ€»é¢„æµ‹æ¬¡æ•°: {len(self.prediction_history)}")
        
        # ç±»åˆ«åˆ†å¸ƒ
        class_counts = Counter([p['prediction'] for p in self.prediction_history])
        safe_print("   é¢„æµ‹ç±»åˆ«åˆ†å¸ƒ:")
        for class_name, count in class_counts.items():
            safe_print(f"      {class_name}: {count} æ¬¡")
        
        # ç½®ä¿¡åº¦ç»Ÿè®¡
        confidences = [p['confidence'] for p in self.prediction_history]
        safe_print(f"   å¹³å‡ç½®ä¿¡åº¦: {np.mean(confidences):.4f}")
        safe_print(f"   æœ€é«˜ç½®ä¿¡åº¦: {np.max(confidences):.4f}")
        safe_print(f"   æœ€ä½ç½®ä¿¡åº¦: {np.min(confidences):.4f}")
    
    def show_prediction_history(self):
        """æ˜¾ç¤ºé¢„æµ‹å†å²"""
        if not self.prediction_history:
            safe_print("   æš‚æ— é¢„æµ‹è®°å½•")
            return
        
        safe_print("\n[ğŸ“–] æœ€è¿‘10æ¬¡é¢„æµ‹å†å²:")
        for i, record in enumerate(self.prediction_history[-10:], 1):
            safe_print(f"   {i}. {record['timestamp'].strftime('%H:%M:%S')} - "
                       f"{record['prediction']} ({record['confidence']:.4f})")
    
    def batch_prediction_mode(self):
        """æ‰¹é‡é¢„æµ‹æ¨¡å¼"""
        safe_print("\n[ğŸ“] æ‰¹é‡é¢„æµ‹æ¨¡å¼")
        safe_print("   è¾“å…¥åŒ…å«å›¾åƒçš„ç›®å½•è·¯å¾„")
        
        dir_path = input("è¯·è¾“å…¥ç›®å½•è·¯å¾„: ").strip()
        
        if not os.path.exists(dir_path):
            safe_print("[âŒ] ç›®å½•ä¸å­˜åœ¨")
            return
        
        # æŸ¥æ‰¾å›¾åƒæ–‡ä»¶
        image_files = []
        for root, dirs, files in os.walk(dir_path):
            for file in files:
                if file.lower().endswith(('.png', '.jpg', '.jpeg')):
                    image_files.append(os.path.join(root, file))
        
        if not image_files:
            safe_print("[âŒ] ç›®å½•ä¸­æœªæ‰¾åˆ°å›¾åƒæ–‡ä»¶")
            return
        
        safe_print(f"   æ‰¾åˆ° {len(image_files)} å¼ å›¾åƒ")
        
        # æ‰¹é‡é¢„æµ‹
        results = []
        for image_path in tqdm(image_files, desc="   æ‰¹é‡é¢„æµ‹"):
            result = self.predict_and_visualize(image_path, save_result=True)
            if result:
                results.append({
                    'path': image_path,
                    'prediction': result['predicted_class'],
                    'confidence': result['confidence']
                })
        
        # ä¿å­˜æ‰¹é‡é¢„æµ‹ç»“æœ
        if results:
            batch_summary_path = f"{self.output_dir}/batch_prediction_summary.txt"
            with open(batch_summary_path, 'w', encoding='utf-8') as f:
                f.write("æ‰¹é‡é¢„æµ‹ç»“æœæ‘˜è¦\n")
                f.write("="*50 + "\n\n")
                f.write(f"å¤„ç†æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
                f.write(f"æ€»å›¾åƒæ•°: {len(image_files)}\n")
                f.write(f"æˆåŠŸé¢„æµ‹: {len(results)}\n\n")
                
                f.write("é¢„æµ‹ç»“æœ:\n")
                for result in results:
                    f.write(f"{result['path']}: {result['prediction']} "
                           f"({result['confidence']:.4f})\n")
                
                # ç»Ÿè®¡
                pred_counts = Counter([r['prediction'] for r in results])
                f.write("\nç±»åˆ«ç»Ÿè®¡:\n")
                for class_name, count in pred_counts.items():
                    f.write(f"{class_name}: {count}\n")
            
            safe_print(f"   [ğŸ’¾] æ‰¹é‡é¢„æµ‹ç»“æœå·²ä¿å­˜: {batch_summary_path}")

def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='ChladniVision Pro - ä¼˜åŒ–ç‰ˆç³»ç»Ÿ')
    parser.add_argument('--train', action='store_true', help='è®­ç»ƒæ¨¡å¼')
    parser.add_argument('--data_dir', type=str, help='æ•°æ®ç›®å½•è·¯å¾„')
    parser.add_argument('--predict', type=str, help='é¢„æµ‹å›¾åƒè·¯å¾„')
    parser.add_argument('--model', type=str, default='chladni_pro_model.pkl', 
                       help='æ¨¡å‹æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--interactive', action='store_true', help='äº¤äº’å¼æ¨¡å¼')
    parser.add_argument('--output_dir', type=str, default='output', 
                       help='è¾“å‡ºç›®å½•')
    parser.add_argument('--demo', action='store_true', help='æ¼”ç¤ºæ¨¡å¼')
    
    args = parser.parse_args()
    
    # åˆ›å»ºç³»ç»Ÿå®ä¾‹
    system = ChladniVisionPro()
    system.output_dir = args.output_dir
    system.welcome_message()
    
    if args.demo:
        # æ¼”ç¤ºæ¨¡å¼
        safe_print("\n[æ¼”ç¤º] æ¼”ç¤ºæ¨¡å¼")
        safe_print("   å°†ä½¿ç”¨å¢å¼ºæ•°æ®é›†è¿›è¡Œå¿«é€Ÿæ¼”ç¤º...")
        
        # ä½¿ç”¨å¢å¼ºæ•°æ®é›†è®­ç»ƒ
        success = system.train('data_augmented/', 'demo_model.pkl')
        if success:
            safe_print("\n[ç›®æ ‡] æ¼”ç¤ºé¢„æµ‹:")
            # æ¼”ç¤ºé¢„æµ‹
            demo_image = 'data/600Hz/600hz_001.png'
            if os.path.exists(demo_image):
                system.predict_and_visualize(demo_image, save_result=True)
            
            # è¿›å…¥äº¤äº’æ¨¡å¼
            system.interactive_mode()
    
    elif args.train:
        # è®­ç»ƒæ¨¡å¼
        if not args.data_dir:
            safe_print("[âŒ] è®­ç»ƒæ¨¡å¼éœ€è¦æŒ‡å®š --data_dir")
            return
        
        success = system.train(args.data_dir, args.model)
        if success and args.interactive:
            system.interactive_mode()
    
    elif args.predict:
        # é¢„æµ‹æ¨¡å¼
        if not system.load_model(args.model):
            return
        
        system.predict_and_visualize(args.predict, save_result=True)
    
    elif args.interactive:
        # äº¤äº’å¼æ¨¡å¼
        if not system.load_model(args.model):
            safe_print("   è¯·å…ˆè®­ç»ƒæ¨¡å‹æˆ–æŒ‡å®šæ­£ç¡®çš„æ¨¡å‹è·¯å¾„")
            return
        
        system.interactive_mode()
    
    else:
        # æ˜¾ç¤ºä½¿ç”¨è¯´æ˜
        safe_print("\n[ğŸ“–] ä½¿ç”¨è¯´æ˜:")
        safe_print("   1. æ¼”ç¤ºæ¨¡å¼ (å¿«é€Ÿä½“éªŒ):")
        safe_print("      python chladni_vision_pro.py --demo")
        safe_print()
        safe_print("   2. è®­ç»ƒæ¨¡å‹:")
        safe_print("      python chladni_vision_pro.py --train --data_dir data/")
        safe_print()
        safe_print("   3. é¢„æµ‹å›¾åƒ:")
        safe_print("      python chladni_vision_pro.py --predict image.png")
        safe_print()
        safe_print("   4. äº¤äº’å¼æ¨¡å¼:")
        safe_print("      python chladni_vision_pro.py --interactive")
        safe_print()
        safe_print("   5. è®­ç»ƒåè¿›å…¥äº¤äº’æ¨¡å¼:")
        safe_print("      python chladni_vision_pro.py --train --data_dir data/ --interactive")
        safe_print()
        safe_print("[ğŸ”§] è¾“å‡ºæ–‡ä»¶:")
        safe_print("   - output/enhanced_confusion_matrix.png (å¢å¼ºæ··æ·†çŸ©é˜µ)")
        safe_print("   - output/model_comparison.png (æ¨¡å‹æ€§èƒ½å¯¹æ¯”)")
        safe_print("   - output/feature_analysis.png (ç‰¹å¾åˆ†æ)")
        safe_print("   - output/enhanced_sample_predictions.png (å¢å¼ºæ ·æœ¬å±•ç¤º)")
        safe_print("   - output/enhanced_prediction_*.png (å¢å¼ºé¢„æµ‹ç»“æœ)")
        safe_print("   - output/detailed_classification_report.txt (è¯¦ç»†æŠ¥å‘Š)")

if __name__ == "__main__":
    main()