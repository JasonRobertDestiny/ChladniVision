#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ä¼˜åŒ–ç‰ˆç‰¹å¾æå–æ¨¡å—
æå‡åˆ†ç±»å‡†ç¡®ç‡çš„é«˜çº§ç‰¹å¾æå–æ–¹æ³•
"""

import cv2
import numpy as np
import os
from sklearn.decomposition import PCA
from sklearn.preprocessing import StandardScaler, RobustScaler
from sklearn.cluster import KMeans, MiniBatchKMeans
from scipy import ndimage
from scipy.spatial.distance import cdist
import warnings
warnings.filterwarnings('ignore')

# ä¿®å¤Windowsç³»ç»Ÿjoblibå¹¶è¡Œå¤„ç†é—®é¢˜
os.environ['LOKY_MAX_CPU_COUNT'] = '4'  # é™åˆ¶æœ€å¤§CPUæ ¸å¿ƒæ•°
os.environ['JOBLIB_START_METHOD'] = 'threading'  # ä½¿ç”¨threadingè€Œä¸æ˜¯multiprocessing

class OptimizedFeatureExtractor:
    """ä¼˜åŒ–ç‰ˆç‰¹å¾æå–å™¨"""
    
    def __init__(self, image_size=(128, 128)):
        self.image_size = image_size
        self.scaler = StandardScaler()  # ä½¿ç”¨StandardScaleræ›¿ä»£RobustScaler
        # ä¼˜åŒ–PCAè®¾ç½®ï¼šä½¿ç”¨å›ºå®šç»´åº¦ï¼Œç¡®ä¿ç‰¹å¾å¤šæ ·æ€§
        self.pca = PCA(n_components=30, random_state=42)  # 30ç»´å¹³è¡¡æ€§èƒ½å’Œå¤šæ ·æ€§
        self.is_fitted = False
        
        # ç‰¹å¾é…ç½®
        self.feature_config = {
            'enhanced_sift': True,
            'advanced_lbp': True,
            'multi_scale_gradient': True,
            'gabor_texture': True,
            'haralick_features': True,
            'enhanced_statistical': True,
            'frequency_domain': True,
            'shape_features': True,
            'edge_features': True,
            'color_features': True
        }
        
        # Gaboræ»¤æ³¢å™¨å‚æ•°
        self.gabor_kernels = self._create_gabor_kernels()
        
        # SIFTè¯æ±‡è¡¨
        self.sift_vocabulary = None
        self.vocabulary_size = 50
        
    def _create_gabor_kernels(self):
        """åˆ›å»ºGaboræ»¤æ³¢å™¨ç»„"""
        kernels = []
        frequencies = [0.1, 0.3, 0.5]
        orientations = [0, 45, 90, 135]
        
        for freq in frequencies:
            for angle in orientations:
                kernel = cv2.getGaborKernel(
                    (21, 21), 3.0, np.deg2rad(angle), 
                    freq, 0.5, 0, ktype=cv2.CV_32F
                )
                kernels.append(kernel)
        
        return kernels
    
    def preprocess_image(self, image):
        """ä¸“é—¨ä¸ºå…‹æ‹‰å°¼å›¾å½¢ä¼˜åŒ–çš„å›¾åƒé¢„å¤„ç†"""
        try:
            # è½¬æ¢ä¸ºç°åº¦
            if len(image.shape) == 3:
                gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
            else:
                gray = image.copy()
            
            # ç¡®ä¿å›¾åƒæ˜¯uint8ç±»å‹
            if gray.dtype != np.uint8:
                if gray.max() <= 1.0:
                    gray = (gray * 255).astype(np.uint8)
                else:
                    gray = np.clip(gray, 0, 255).astype(np.uint8)
            
            # è°ƒæ•´å°ºå¯¸ - ä½¿ç”¨æ›´å¥½çš„æ’å€¼æ–¹æ³•
            resized = cv2.resize(gray, self.image_size, interpolation=cv2.INTER_CUBIC)
            
            # å…‹æ‹‰å°¼å›¾å½¢ä¸“ç”¨å¤„ç†ï¼šå¢å¼ºå¯¹æ¯”åº¦
            # ä½¿ç”¨æ›´æ¸©å’Œçš„CLAHEè®¾ç½®
            clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(4, 4))
            enhanced = clahe.apply(resized)
            
            # è½»å¾®çš„é«˜æ–¯æ¨¡ç³Šå»å™ªï¼Œä¿ç•™è¾¹ç¼˜ç»†èŠ‚
            denoised = cv2.GaussianBlur(enhanced, (3, 3), 0.5)
            
            # äºŒå€¼åŒ–å¤„ç† - å¯¹å…‹æ‹‰å°¼å›¾å½¢å¾ˆé‡è¦
            _, binary = cv2.threshold(denoised, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
            
            # å½¢æ€å­¦æ“ä½œæ¸…ç†å™ªç‚¹
            kernel = np.ones((2, 2), np.uint8)
            cleaned = cv2.morphologyEx(binary, cv2.MORPH_CLOSE, kernel)
            cleaned = cv2.morphologyEx(cleaned, cv2.MORPH_OPEN, kernel)
            
            # å½’ä¸€åŒ–åˆ°[0,1]èŒƒå›´
            normalized = cleaned.astype(np.float32) / 255.0
            
            return normalized
            
        except Exception as e:
            print(f"å…‹æ‹‰å°¼å›¾å½¢é¢„å¤„ç†å¤±è´¥: {e}")
            # å¤‡ç”¨ç®€å•å¤„ç†
            try:
                if len(image.shape) == 3:
                    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
                else:
                    gray = image
                
                # ç¡®ä¿æ­£ç¡®çš„æ•°æ®ç±»å‹
                if gray.dtype != np.uint8:
                    gray = np.clip(gray * 255 if gray.max() <= 1.0 else gray, 0, 255).astype(np.uint8)
                
                resized = cv2.resize(gray, self.image_size, interpolation=cv2.INTER_AREA)
                normalized = resized.astype(np.float32) / 255.0
                return normalized
            except Exception as e2:
                print(f"å¤‡ç”¨å¤„ç†ä¹Ÿå¤±è´¥: {e2}")
                return np.zeros(self.image_size, dtype=np.float32)
    
    def extract_enhanced_sift_features(self, image):
        """æå–å¢å¼ºçš„SIFTç‰¹å¾"""
        try:
            img_uint8 = (image * 255).astype(np.uint8)
            
            # å¢å¼ºSIFTå‚æ•°
            sift = cv2.SIFT_create(
                nfeatures=100,           # å¢åŠ å…³é”®ç‚¹æ•°é‡
                nOctaveLayers=5,         # å¢åŠ  octave å±‚æ•°
                contrastThreshold=0.02,  # é™ä½å¯¹æ¯”åº¦é˜ˆå€¼
                edgeThreshold=20,        # å¢åŠ è¾¹ç¼˜é˜ˆå€¼
                sigma=1.6                # é«˜æ–¯æ¨¡ç³Šå‚æ•°
            )
            
            keypoints, descriptors = sift.detectAndCompute(img_uint8, None)
            
            if descriptors is not None and len(descriptors) >= 10:
                # ä½¿ç”¨MiniBatchKMeansåŠ é€Ÿèšç±»
                if self.sift_vocabulary is None:
                    # é¦–æ¬¡è¿è¡Œï¼Œåˆ›å»ºè¯æ±‡è¡¨
                    kmeans = MiniBatchKMeans(
                        n_clusters=min(self.vocabulary_size, len(descriptors)),
                        random_state=42, batch_size=100
                    )
                    kmeans.fit(descriptors)
                    self.sift_vocabulary = kmeans
                else:
                    kmeans = self.sift_vocabulary
                
                # è®¡ç®—è§†è§‰è¯è¢‹
                hist = np.zeros(self.vocabulary_size)
                for d in descriptors:
                    cluster_idx = kmeans.predict([d])[0]
                    hist[cluster_idx] += 1
                
                # å½’ä¸€åŒ–
                hist = hist / (np.sum(hist) + 1e-7)
                
                # æ·»åŠ ç»Ÿè®¡ç‰¹å¾
                if len(descriptors) > 0:
                    keypoint_info = np.array([
                        len(keypoints),
                        np.mean([kp.size for kp in keypoints]),
                        np.std([kp.size for kp in keypoints]),
                        np.mean([kp.angle for kp in keypoints]),
                        np.std([kp.angle for kp in keypoints]),
                        np.mean([kp.response for kp in keypoints]),
                        np.std([kp.response for kp in keypoints])
                    ])
                else:
                    keypoint_info = np.zeros(7)
                
                return np.concatenate([hist, keypoint_info])
            
            return np.zeros(self.vocabulary_size + 7)
            
        except Exception as e:
            return np.zeros(self.vocabulary_size + 7)
    
    def extract_advanced_lbp_features(self, image):
        """æå–é«˜çº§LBPç‰¹å¾"""
        try:
            img_uint8 = (image * 255).astype(np.uint8)
            
            # å¤šå°ºåº¦LBP
            lbp_features = []
            radii = [1, 2, 3, 4]
            n_points = [8, 16, 24, 32]
            
            for radius, n_point in zip(radii, n_points):
                lbp = self._compute_lbp(img_uint8, radius, n_point)
                
                # è®¡ç®—LBPç»Ÿè®¡ç‰¹å¾
                hist, _ = np.histogram(lbp.ravel(), bins=256, range=(0, 256))
                hist = hist.astype(np.float32)
                hist = hist / (np.sum(hist) + 1e-7)
                
                # æ·»åŠ ç»Ÿè®¡é‡
                stats = [
                    np.mean(lbp),
                    np.std(lbp),
                    np.var(lbp),
                    np.percentile(lbp, 25),
                    np.percentile(lbp, 75)
                ]
                
                lbp_features.extend([hist[::8]])  # é™ç»´
                lbp_features.extend(stats)
            
            return np.concatenate(lbp_features)
            
        except Exception as e:
            return np.zeros(4 * 32 + 4 * 5)  # 4 scales * 32 bins + 4 scales * 5 stats
    
    def _compute_lbp(self, image, radius, n_points):
        """è®¡ç®—LBPç‰¹å¾"""
        h, w = image.shape
        lbp = np.zeros((h, w), dtype=np.uint8)
        
        for i in range(radius, h - radius):
            for j in range(radius, w - radius):
                center = image[i, j]
                code = 0
                
                for k in range(n_points):
                    angle = 2 * np.pi * k / n_points
                    x = i + radius * np.cos(angle)
                    y = j + radius * np.sin(angle)
                    
                    if 0 <= x < h and 0 <= y < w:
                        if image[int(x), int(y)] >= center:
                            code += 2**k
                
                lbp[i, j] = code
        
        return lbp
    
    def extract_multi_scale_gradient_features(self, image):
        """æå–å¤šå°ºåº¦æ¢¯åº¦ç‰¹å¾"""
        try:
            features = []
            
            # å¤šå°ºåº¦Sobelç®—å­
            scales = [1, 3, 5]
            for scale in scales:
                # é«˜æ–¯æ»¤æ³¢
                blurred = cv2.GaussianBlur(image, (scale, scale), 0)
                
                # Sobelæ¢¯åº¦
                sobel_x = cv2.Sobel(blurred, cv2.CV_64F, 1, 0, ksize=3)
                sobel_y = cv2.Sobel(blurred, cv2.CV_64F, 0, 1, ksize=3)
                
                # æ¢¯åº¦å¹…å€¼å’Œæ–¹å‘
                gradient_mag = np.sqrt(sobel_x**2 + sobel_y**2)
                gradient_dir = np.arctan2(sobel_y, sobel_x)
                
                # ç»Ÿè®¡ç‰¹å¾
                features.extend([
                    np.mean(gradient_mag),
                    np.std(gradient_mag),
                    np.max(gradient_mag),
                    np.min(gradient_mag),
                    np.percentile(gradient_mag, 25),
                    np.percentile(gradient_mag, 75),
                    np.percentile(gradient_mag, 90),
                    np.percentile(gradient_mag, 95)
                ])
                
                # æ–¹å‘ç‰¹å¾
                features.extend([
                    np.mean(gradient_dir),
                    np.std(gradient_dir),
                    np.max(gradient_dir),
                    np.min(gradient_dir)
                ])
                
                # æ¢¯åº¦ç›´æ–¹å›¾
                hist, _ = np.histogram(gradient_dir.ravel(), bins=8, range=(-np.pi, np.pi))
                hist = hist.astype(np.float32)
                hist = hist / (np.sum(hist) + 1e-7)
                features.extend(hist)
            
            return np.array(features)
            
        except Exception as e:
            return np.zeros(3 * 12 + 3 * 8)  # 3 scales * 12 stats + 3 scales * 8 hist bins
    
    def extract_gabor_texture_features(self, image):
        """æå–Gaborçº¹ç†ç‰¹å¾"""
        try:
            img_uint8 = (image * 255).astype(np.uint8)
            features = []
            
            # åº”ç”¨æ¯ä¸ªGaboræ»¤æ³¢å™¨
            for kernel in self.gabor_kernels:
                filtered = cv2.filter2D(img_uint8, cv2.CV_8UC3, kernel)
                
                # è®¡ç®—æ»¤æ³¢åçš„ç»Ÿè®¡ç‰¹å¾
                features.extend([
                    np.mean(filtered),
                    np.std(filtered),
                    np.var(filtered),
                    np.max(filtered),
                    np.min(filtered),
                    np.percentile(filtered, 25),
                    np.percentile(filtered, 75)
                ])
                
                # èƒ½é‡ç‰¹å¾
                energy = np.sum(filtered**2)
                features.append(energy)
            
            return np.array(features)
            
        except Exception as e:
            return np.zeros(len(self.gabor_kernels) * 8)
    
    def extract_haralick_features(self, image):
        """æå–Haralickçº¹ç†ç‰¹å¾"""
        try:
            img_uint8 = (image * 255).astype(np.uint8)
            
            # è®¡ç®—ç°åº¦å…±ç”ŸçŸ©é˜µ
            distances = [1, 2, 3]
            angles = [0, 45, 90, 135]
            
            haralick_features = []
            
            for distance in distances:
                for angle in angles:
                    # ç®€åŒ–çš„Haralickç‰¹å¾è®¡ç®—
                    # ä½¿ç”¨ç°åº¦çº§å‡å°‘è®¡ç®—é‡
                    quantized = (img_uint8 // 32).astype(np.uint8)
                    
                    # è®¡ç®—å…±ç”ŸçŸ©é˜µ
                    glcm = self._compute_glcm(quantized, distance, angle)
                    
                    # è®¡ç®—Haralickç‰¹å¾
                    features = self._compute_haralick_stats(glcm)
                    haralick_features.extend(features)
            
            return np.array(haralick_features)
            
        except Exception as e:
            return np.zeros(3 * 4 * 6)  # 3 distances * 4 angles * 6 features
    
    def _compute_glcm(self, image, distance, angle):
        """è®¡ç®—ç°åº¦å…±ç”ŸçŸ©é˜µ"""
        h, w = image.shape
        max_level = 8  # ç°åº¦çº§
        glcm = np.zeros((max_level, max_level))
        
        # è½¬æ¢è§’åº¦ä¸ºå¼§åº¦
        angle_rad = np.deg2rad(angle)
        
        # è®¡ç®—åç§»é‡
        dx = int(round(distance * np.cos(angle_rad)))
        dy = int(round(distance * np.sin(angle_rad)))
        
        # å¡«å……å…±ç”ŸçŸ©é˜µ
        for i in range(max(0, -dy), min(h, h - dy)):
            for j in range(max(0, -dx), min(w, w - dx)):
                i2, j2 = i + dy, j + dx
                if 0 <= i2 < h and 0 <= j2 < w:
                    val1 = image[i, j]
                    val2 = image[i2, j2]
                    glcm[val1, val2] += 1
        
        # å½’ä¸€åŒ–
        glcm = glcm / (np.sum(glcm) + 1e-7)
        return glcm
    
    def _compute_haralick_stats(self, glcm):
        """è®¡ç®—Haralickç»Ÿè®¡ç‰¹å¾"""
        try:
            # è®¡ç®—Haralickç‰¹å¾çš„ç®€åŒ–ç‰ˆæœ¬
            h, w = glcm.shape
            
            # å¯¹æ¯”åº¦
            contrast = 0
            for i in range(h):
                for j in range(w):
                    contrast += (i - j)**2 * glcm[i, j]
            
            # èƒ½é‡
            energy = np.sum(glcm**2)
            
            # ç†µ
            entropy = 0
            for i in range(h):
                for j in range(w):
                    if glcm[i, j] > 0:
                        entropy -= glcm[i, j] * np.log(glcm[i, j] + 1e-7)
            
            # å‡å€¼
            mean_i = np.sum(i * glcm[i, j] for i in range(h) for j in range(w))
            mean_j = np.sum(j * glcm[i, j] for i in range(h) for j in range(w))
            
            # æ–¹å·®
            variance_i = np.sum((i - mean_i)**2 * glcm[i, j] for i in range(h) for j in range(w))
            variance_j = np.sum((j - mean_j)**2 * glcm[i, j] for i in range(h) for j in range(w))
            
            return [contrast, energy, entropy, variance_i, variance_j, (variance_i + variance_j) / 2]
            
        except Exception as e:
            return [0] * 6
    
    def extract_enhanced_statistical_features(self, image):
        """æå–å¢å¼ºçš„ç»Ÿè®¡ç‰¹å¾"""
        try:
            features = []
            
            # åŸºæœ¬ç»Ÿè®¡
            features.extend([
                np.mean(image),
                np.std(image),
                np.var(image),
                np.min(image),
                np.max(image),
                np.median(image),
                np.percentile(image, 10),
                np.percentile(image, 25),
                np.percentile(image, 75),
                np.percentile(image, 90)
            ])
            
            # é«˜é˜¶ç»Ÿè®¡
            features.extend([
                self._skewness(image),
                self._kurtosis(image),
                self._entropy(image)
            ])
            
            # å½¢çŠ¶ç‰¹å¾
            features.extend([
                np.sum(image > np.mean(image)) / image.size,  # è¶…è¿‡å‡å€¼çš„åƒç´ æ¯”ä¾‹
                np.sum(image < np.mean(image)) / image.size,  # ä½äºå‡å€¼çš„åƒç´ æ¯”ä¾‹
                np.sum(image > np.percentile(image, 75)) / image.size,  # é«˜äº®åº¦åƒç´ æ¯”ä¾‹
                np.sum(image < np.percentile(image, 25)) / image.size   # ä½äº®åº¦åƒç´ æ¯”ä¾‹
            ])
            
            # å±€éƒ¨ç»Ÿè®¡ç‰¹å¾
            h, w = image.shape
            blocks = [(0, h//2, 0, w//2), (0, h//2, w//2, w), 
                     (h//2, h, 0, w//2), (h//2, h, w//2, w)]
            
            for i1, i2, j1, j2 in blocks:
                block = image[i1:i2, j1:j2]
                features.extend([
                    np.mean(block),
                    np.std(block),
                    np.max(block),
                    np.min(block)
                ])
            
            return np.array(features)
            
        except Exception as e:
            return np.zeros(10 + 3 + 4 + 4 * 4)  # åŸºæœ¬ç»Ÿè®¡ + é«˜é˜¶ç»Ÿè®¡ + å½¢çŠ¶ç‰¹å¾ + å±€éƒ¨ç»Ÿè®¡
    
    def _skewness(self, data):
        """è®¡ç®—ååº¦"""
        mean = np.mean(data)
        std = np.std(data)
        if std == 0:
            return 0
        return np.mean(((data - mean) / std)**3)
    
    def _kurtosis(self, data):
        """è®¡ç®—å³°åº¦"""
        mean = np.mean(data)
        std = np.std(data)
        if std == 0:
            return 0
        return np.mean(((data - mean) / std)**4) - 3
    
    def _entropy(self, data):
        """è®¡ç®—ç†µ"""
        hist, _ = np.histogram(data, bins=256, range=(0, 1))
        hist = hist / (np.sum(hist) + 1e-7)
        entropy = 0
        for p in hist:
            if p > 0:
                entropy -= p * np.log(p + 1e-7)
        return entropy
    
    def extract_frequency_domain_features(self, image):
        """æå–é¢‘åŸŸç‰¹å¾"""
        try:
            # å‚…é‡Œå¶å˜æ¢
            f_transform = np.fft.fft2(image)
            f_shift = np.fft.fftshift(f_transform)
            magnitude_spectrum = np.abs(f_shift)
            
            features = []
            
            # é¢‘åŸŸèƒ½é‡åˆ†å¸ƒ
            h, w = magnitude_spectrum.shape
            center_h, center_w = h // 2, w // 2
            
            # ç¯å½¢èƒ½é‡åˆ†å¸ƒ
            radii = [5, 10, 15, 20, 25, 30, 35, 40]
            for radius in radii:
                if radius < min(center_h, center_w):
                    y, x = np.ogrid[:h, :w]
                    mask = (x - center_w)**2 + (y - center_h)**2 <= radius**2
                    
                    if radius > 5:
                        inner_mask = (x - center_w)**2 + (y - center_h)**2 <= (radius-5)**2
                        mask = mask & ~inner_mask
                    
                    energy = np.sum(magnitude_spectrum[mask])
                    features.append(energy)
            
            # è±¡é™èƒ½é‡åˆ†å¸ƒ
            total_energy = np.sum(magnitude_spectrum)
            if total_energy > 0:
                q1 = np.sum(magnitude_spectrum[:center_h, :center_w]) / total_energy
                q2 = np.sum(magnitude_spectrum[:center_h, center_w:]) / total_energy
                q3 = np.sum(magnitude_spectrum[center_h:, :center_w]) / total_energy
                q4 = np.sum(magnitude_spectrum[center_h:, center_w:]) / total_energy
                features.extend([q1, q2, q3, q4])
            else:
                features.extend([0, 0, 0, 0])
            
            # é¢‘è°±ç»Ÿè®¡ç‰¹å¾
            features.extend([
                np.mean(magnitude_spectrum),
                np.std(magnitude_spectrum),
                np.max(magnitude_spectrum),
                np.percentile(magnitude_spectrum, 90),
                np.percentile(magnitude_spectrum, 95)
            ])
            
            return np.array(features)
            
        except Exception as e:
            return np.zeros(8 + 4 + 5)  # ç¯å½¢èƒ½é‡ + è±¡é™èƒ½é‡ + é¢‘è°±ç»Ÿè®¡
    
    def extract_shape_features(self, image):
        """æå–å½¢çŠ¶ç‰¹å¾"""
        try:
            img_uint8 = (image * 255).astype(np.uint8)
            
            # äºŒå€¼åŒ–
            _, binary = cv2.threshold(img_uint8, 128, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
            
            # å½¢æ€å­¦æ“ä½œ
            kernel = np.ones((3, 3), np.uint8)
            cleaned = cv2.morphologyEx(binary, cv2.MORPH_OPEN, kernel)
            
            # æŸ¥æ‰¾è½®å»“
            contours, _ = cv2.findContours(cleaned, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
            
            features = []
            
            if contours:
                # æœ€å¤§è½®å»“
                largest_contour = max(contours, key=cv2.contourArea)
                
                # è½®å»“ç‰¹å¾
                area = cv2.contourArea(largest_contour)
                perimeter = cv2.arcLength(largest_contour, True)
                
                if perimeter > 0:
                    circularity = 4 * np.pi * area / (perimeter**2)
                else:
                    circularity = 0
                
                # è¾¹ç•Œæ¡†
                x, y, w, h = cv2.boundingRect(largest_contour)
                aspect_ratio = w / h if h > 0 else 0
                
                # å‡¸åŒ…
                hull = cv2.convexHull(largest_contour)
                hull_area = cv2.contourArea(hull)
                solidity = area / hull_area if hull_area > 0 else 0
                
                features.extend([
                    area, perimeter, circularity, aspect_ratio, solidity,
                    len(contours),  # è½®å»“æ•°é‡
                    w, h,           # è¾¹ç•Œæ¡†å°ºå¯¸
                    len(largest_contour)  # è½®å»“ç‚¹æ•°
                ])
            else:
                features = [0] * 9
            
            return np.array(features)
            
        except Exception as e:
            return np.zeros(9)
    
    def extract_edge_features(self, image):
        """æå–è¾¹ç¼˜ç‰¹å¾"""
        try:
            img_uint8 = (image * 255).astype(np.uint8)
            
            features = []
            
            # å¤šé˜ˆå€¼è¾¹ç¼˜æ£€æµ‹
            thresholds = [50, 100, 150, 200]
            for threshold in thresholds:
                edges = cv2.Canny(img_uint8, threshold//2, threshold)
                
                # è¾¹ç¼˜ç»Ÿè®¡
                edge_density = np.sum(edges > 0) / edges.size
                edge_length = np.sum(edges > 0)
                
                features.extend([edge_density, edge_length])
            
            # Sobelè¾¹ç¼˜å¼ºåº¦
            sobel_x = cv2.Sobel(img_uint8, cv2.CV_64F, 1, 0, ksize=3)
            sobel_y = cv2.Sobel(img_uint8, cv2.CV_64F, 0, 1, ksize=3)
            sobel_mag = np.sqrt(sobel_x**2 + sobel_y**2)
            
            features.extend([
                np.mean(sobel_mag),
                np.std(sobel_mag),
                np.max(sobel_mag),
                np.percentile(sobel_mag, 75),
                np.percentile(sobel_mag, 90)
            ])
            
            return np.array(features)
            
        except Exception as e:
            return np.zeros(4 * 2 + 5)  # 4 thresholds * 2 features + 5 sobel features
    
    def extract_color_features(self, image):
        """æå–é¢œè‰²ç‰¹å¾ï¼ˆå¦‚æœæ˜¯å½©è‰²å›¾åƒï¼‰"""
        try:
            # å¦‚æœæ˜¯ç°åº¦å›¾åƒï¼Œè¿”å›é›¶å‘é‡
            if len(image.shape) == 2:
                return np.zeros(15)
            
            # è½¬æ¢ä¸ºä¸åŒé¢œè‰²ç©ºé—´
            img_uint8 = (image * 255).astype(np.uint8)
            
            # RGBç©ºé—´
            r, g, b = cv2.split(img_uint8)
            
            # HSVç©ºé—´
            hsv = cv2.cvtColor(img_uint8, cv2.COLOR_BGR2HSV)
            h, s, v = cv2.split(hsv)
            
            features = []
            
            # RGBç»Ÿè®¡
            for channel in [r, g, b]:
                features.extend([
                    np.mean(channel),
                    np.std(channel),
                    np.max(channel),
                    np.min(channel)
                ])
            
            # HSVç»Ÿè®¡
            features.extend([
                np.mean(h), np.std(h),
                np.mean(s), np.std(s),
                np.mean(v), np.std(v)
            ])
            
            # é¢œè‰²çŸ©
            features.extend([
                np.mean(img_uint8),
                np.std(img_uint8),
                np.var(img_uint8)
            ])
            
            return np.array(features)
            
        except Exception as e:
            return np.zeros(15)
    
    def extract_all_features(self, images):
        """æå–æ‰€æœ‰ç‰¹å¾"""
        print("ğŸ” æå–ä¼˜åŒ–ç‰ˆå¤šæ¨¡æ€ç‰¹å¾...")
        
        all_features = []
        
        for i, image in enumerate(images):
            try:
                # é¢„å¤„ç†
                processed_image = self.preprocess_image(image)
                
                feature_vector = []
                
                # æå–å„ç§ç‰¹å¾
                if self.feature_config['enhanced_sift']:
                    features = self.extract_enhanced_sift_features(processed_image)
                    feature_vector.extend(features)
                
                if self.feature_config['advanced_lbp']:
                    features = self.extract_advanced_lbp_features(processed_image)
                    feature_vector.extend(features)
                
                if self.feature_config['multi_scale_gradient']:
                    features = self.extract_multi_scale_gradient_features(processed_image)
                    feature_vector.extend(features)
                
                if self.feature_config['gabor_texture']:
                    features = self.extract_gabor_texture_features(processed_image)
                    feature_vector.extend(features)
                
                if self.feature_config['haralick_features']:
                    features = self.extract_haralick_features(processed_image)
                    feature_vector.extend(features)
                
                if self.feature_config['enhanced_statistical']:
                    features = self.extract_enhanced_statistical_features(processed_image)
                    feature_vector.extend(features)
                
                if self.feature_config['frequency_domain']:
                    features = self.extract_frequency_domain_features(processed_image)
                    feature_vector.extend(features)
                
                if self.feature_config['shape_features']:
                    features = self.extract_shape_features(processed_image)
                    feature_vector.extend(features)
                
                if self.feature_config['edge_features']:
                    features = self.extract_edge_features(processed_image)
                    feature_vector.extend(features)
                
                if self.feature_config['color_features']:
                    features = self.extract_color_features(processed_image)
                    feature_vector.extend(features)
                
                # æ¸…ç†å¼‚å¸¸å€¼
                feature_vector = np.nan_to_num(feature_vector, nan=0.0)
                all_features.append(feature_vector)
                
            except Exception as e:
                print(f"ç‰¹å¾æå–å¤±è´¥ (å›¾åƒ {i}): {e}")
                # ä½¿ç”¨é›¶å‘é‡
                total_dims = self._get_total_feature_dimensions()
                all_features.append(np.zeros(total_dims))
        
        features = np.array(all_features)
        features = np.nan_to_num(features, nan=0.0)
        
        print(f"âœ… ç‰¹å¾æå–å®Œæˆï¼Œç»´åº¦: {features.shape[1]}")
        
        # ä¿å­˜ç‰¹å¾ç»´åº¦ä¿¡æ¯
        self.n_features = features.shape[1]
        
        return features
    
    def _get_total_feature_dimensions(self):
        """è®¡ç®—æ€»ç‰¹å¾ç»´åº¦"""
        dimensions = 0
        
        if self.feature_config['enhanced_sift']:
            dimensions += 50 + 7  # SIFTè¯æ±‡è¡¨ + å…³é”®ç‚¹ä¿¡æ¯
        
        if self.feature_config['advanced_lbp']:
            dimensions += 4 * 32 + 4 * 5  # 4 scales * 32 bins + 4 scales * 5 stats
        
        if self.feature_config['multi_scale_gradient']:
            dimensions += 3 * 12 + 3 * 8  # 3 scales * 12 stats + 3 scales * 8 hist bins
        
        if self.feature_config['gabor_texture']:
            dimensions += len(self.gabor_kernels) * 8  # 12 kernels * 8 features
        
        if self.feature_config['haralick_features']:
            dimensions += 3 * 4 * 6  # 3 distances * 4 angles * 6 features
        
        if self.feature_config['enhanced_statistical']:
            dimensions += 10 + 3 + 4 + 4 * 4  # åŸºæœ¬ç»Ÿè®¡ + é«˜é˜¶ç»Ÿè®¡ + å½¢çŠ¶ç‰¹å¾ + å±€éƒ¨ç»Ÿè®¡
        
        if self.feature_config['frequency_domain']:
            dimensions += 8 + 4 + 5  # ç¯å½¢èƒ½é‡ + è±¡é™èƒ½é‡ + é¢‘è°±ç»Ÿè®¡
        
        if self.feature_config['shape_features']:
            dimensions += 9  # å½¢çŠ¶ç‰¹å¾
        
        if self.feature_config['edge_features']:
            dimensions += 4 * 2 + 5  # 4 thresholds * 2 features + 5 sobel features
        
        if self.feature_config['color_features']:
            dimensions += 15  # é¢œè‰²ç‰¹å¾
        
        return dimensions
    
    def optimize_features(self, X_features):
        """ç‰¹å¾ä¼˜åŒ–å¤„ç†"""
        print("ğŸ”§ ä¼˜åŒ–ç‰¹å¾å¤„ç†...")
        
        # ç‰¹å¾æ ‡å‡†åŒ–
        X_scaled = self.scaler.fit_transform(X_features)
        
        # PCAé™ç»´
        X_pca = self.pca.fit_transform(X_scaled)
        
        print(f"âœ… ç‰¹å¾ä¼˜åŒ–å®Œæˆ: {X_scaled.shape[1]} â†’ {X_pca.shape[1]}")
        
        self.is_fitted = True
        
        return X_pca
    
    def transform_features(self, X_features):
        """è½¬æ¢æ–°ç‰¹å¾ï¼ˆç”¨äºé¢„æµ‹ï¼‰"""
        if not self.is_fitted:
            raise ValueError("ç‰¹å¾æå–å™¨æœªè®­ç»ƒï¼Œè¯·å…ˆè°ƒç”¨ optimize_features")
        
        # æ ‡å‡†åŒ–
        X_scaled = self.scaler.transform(X_features)
        
        # PCAé™ç»´
        X_pca = self.pca.transform(X_scaled)
        
        return X_pca